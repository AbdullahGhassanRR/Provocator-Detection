{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae734941-a42a-4c6d-b109-a783d3e0f610",
   "metadata": {},
   "source": [
    "# Metodologi \n",
    "# Preprocessing -> Sentiment Classification -> Topic Modelling -> Algoritma Deteksi Provokator per Topik "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "615474dd-605e-4b0f-ae6e-29f6a5212931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>tweet</th>\n",
       "      <th>mentions</th>\n",
       "      <th>replies_count</th>\n",
       "      <th>retweets_count</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1258425982907637761</td>\n",
       "      <td>2020-05-07</td>\n",
       "      <td>23:58:29</td>\n",
       "      <td>1058474317</td>\n",
       "      <td>monologis_id</td>\n",
       "      <td>https://bit.ly/2L6CcbB  | Seharusnya saat ini...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1258320972198940675</td>\n",
       "      <td>2020-05-07</td>\n",
       "      <td>23:57:30</td>\n",
       "      <td>1179769476</td>\n",
       "      <td>its_dul</td>\n",
       "      <td>Klo kata gw Pemerintah tuh lagi menerapkan Her...</td>\n",
       "      <td>['mas__piyuuu']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1258356644427083777</td>\n",
       "      <td>2020-05-07</td>\n",
       "      <td>23:53:20</td>\n",
       "      <td>1012156669831229441</td>\n",
       "      <td>meonkbaong</td>\n",
       "      <td>Saat ini yang bisa saya lakukan hanya menyiapk...</td>\n",
       "      <td>['oiivert']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1258424368993931265</td>\n",
       "      <td>2020-05-07</td>\n",
       "      <td>23:52:04</td>\n",
       "      <td>1204303690061844481</td>\n",
       "      <td>rakyatdotnews</td>\n",
       "      <td>Satu Warga Positif Corona, Bupati: Kondisi ini...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['#rakyatdotnews', '#referensiterkini', '#raky...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1258423545698246656</td>\n",
       "      <td>2020-05-07</td>\n",
       "      <td>23:48:48</td>\n",
       "      <td>227620381</td>\n",
       "      <td>annisathalib_</td>\n",
       "      <td>emosi bgt, lg kondisi begini gue disuruh liput...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['#dirumahaja']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>1258122222931251200</td>\n",
       "      <td>2020-05-07</td>\n",
       "      <td>03:51:27</td>\n",
       "      <td>868057794666037249</td>\n",
       "      <td>gemawonorejo</td>\n",
       "      <td>Informasi Desa Wonorejo :\\n\\nMenindaklanjuti H...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>1258075937360371719</td>\n",
       "      <td>2020-05-07</td>\n",
       "      <td>03:43:49</td>\n",
       "      <td>1250548142400958464</td>\n",
       "      <td>covid_19chinese</td>\n",
       "      <td>Semoga pemerintah benar-benar serius. Saya har...</td>\n",
       "      <td>['sitiftmwti', 'mn_choo', 'dennyyap1', 'lesyeu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>1258075937360371719</td>\n",
       "      <td>2020-05-07</td>\n",
       "      <td>03:31:41</td>\n",
       "      <td>1240834881891909632</td>\n",
       "      <td>sitiftmwti</td>\n",
       "      <td>Pemerintah dalam hal serius menangani Covid in...</td>\n",
       "      <td>['covid_19chinese', 'mn_choo', 'dennyyap1', 'l...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>1258116968185335809</td>\n",
       "      <td>2020-05-07</td>\n",
       "      <td>03:30:34</td>\n",
       "      <td>921740399437283330</td>\n",
       "      <td>freemasonryid</td>\n",
       "      <td>\"Termutakhir, Salah seorang petinggi militer A...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>1258004302527778819</td>\n",
       "      <td>2020-05-07</td>\n",
       "      <td>03:28:29</td>\n",
       "      <td>96579099</td>\n",
       "      <td>r_riil</td>\n",
       "      <td>Apakah instruksi Menhub juga bagian dari fokus...</td>\n",
       "      <td>['jokowi']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0      conversation_id        date      time  \\\n",
       "0             0  1258425982907637761  2020-05-07  23:58:29   \n",
       "1             1  1258320972198940675  2020-05-07  23:57:30   \n",
       "2             2  1258356644427083777  2020-05-07  23:53:20   \n",
       "3             3  1258424368993931265  2020-05-07  23:52:04   \n",
       "4             4  1258423545698246656  2020-05-07  23:48:48   \n",
       "..          ...                  ...         ...       ...   \n",
       "995         995  1258122222931251200  2020-05-07  03:51:27   \n",
       "996         996  1258075937360371719  2020-05-07  03:43:49   \n",
       "997         997  1258075937360371719  2020-05-07  03:31:41   \n",
       "998         998  1258116968185335809  2020-05-07  03:30:34   \n",
       "999         999  1258004302527778819  2020-05-07  03:28:29   \n",
       "\n",
       "                 user_id         username  \\\n",
       "0             1058474317     monologis_id   \n",
       "1             1179769476          its_dul   \n",
       "2    1012156669831229441       meonkbaong   \n",
       "3    1204303690061844481    rakyatdotnews   \n",
       "4              227620381    annisathalib_   \n",
       "..                   ...              ...   \n",
       "995   868057794666037249     gemawonorejo   \n",
       "996  1250548142400958464  covid_19chinese   \n",
       "997  1240834881891909632       sitiftmwti   \n",
       "998   921740399437283330    freemasonryid   \n",
       "999             96579099           r_riil   \n",
       "\n",
       "                                                 tweet  \\\n",
       "0     https://bit.ly/2L6CcbB  | Seharusnya saat ini...   \n",
       "1    Klo kata gw Pemerintah tuh lagi menerapkan Her...   \n",
       "2    Saat ini yang bisa saya lakukan hanya menyiapk...   \n",
       "3    Satu Warga Positif Corona, Bupati: Kondisi ini...   \n",
       "4    emosi bgt, lg kondisi begini gue disuruh liput...   \n",
       "..                                                 ...   \n",
       "995  Informasi Desa Wonorejo :\\n\\nMenindaklanjuti H...   \n",
       "996  Semoga pemerintah benar-benar serius. Saya har...   \n",
       "997  Pemerintah dalam hal serius menangani Covid in...   \n",
       "998  \"Termutakhir, Salah seorang petinggi militer A...   \n",
       "999  Apakah instruksi Menhub juga bagian dari fokus...   \n",
       "\n",
       "                                              mentions  replies_count  \\\n",
       "0                                                   []              0   \n",
       "1                                      ['mas__piyuuu']              0   \n",
       "2                                          ['oiivert']              0   \n",
       "3                                                   []              0   \n",
       "4                                                   []              0   \n",
       "..                                                 ...            ...   \n",
       "995                                                 []              0   \n",
       "996  ['sitiftmwti', 'mn_choo', 'dennyyap1', 'lesyeu...              1   \n",
       "997  ['covid_19chinese', 'mn_choo', 'dennyyap1', 'l...              1   \n",
       "998                                                 []              0   \n",
       "999                                         ['jokowi']              0   \n",
       "\n",
       "     retweets_count  likes_count  \\\n",
       "0                 3            0   \n",
       "1                 0            0   \n",
       "2                 0            0   \n",
       "3                 0            0   \n",
       "4                 0            0   \n",
       "..              ...          ...   \n",
       "995               0            0   \n",
       "996               0            0   \n",
       "997               0            0   \n",
       "998               0            0   \n",
       "999               0            0   \n",
       "\n",
       "                                              hashtags  \n",
       "0                                                   []  \n",
       "1                                                   []  \n",
       "2                                                   []  \n",
       "3    ['#rakyatdotnews', '#referensiterkini', '#raky...  \n",
       "4                                      ['#dirumahaja']  \n",
       "..                                                 ...  \n",
       "995                                                 []  \n",
       "996                                                 []  \n",
       "997                                                 []  \n",
       "998                                                 []  \n",
       "999                                                 []  \n",
       "\n",
       "[1000 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('demo_data.csv')\n",
    "df2 = pd.read_csv('final_data.csv')\n",
    "\n",
    "df\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47e1ab17-6cef-4ca6-ad7e-4dabd769b429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1260 entries, 0 to 1259\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  1260 non-null   int64 \n",
      " 1   text        1260 non-null   object\n",
      " 2   sentiment   1260 non-null   object\n",
      " 3   clean_text  1260 non-null   object\n",
      " 4   label       1260 non-null   int64 \n",
      " 5   username    1000 non-null   object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 59.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df['username'] = df2['username']\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46fbe1e3-2d32-48d0-a6cf-e750ba8444f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbceb82c-89cb-43e2-8315-212b5e7149d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>label</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>meski masa kampanye sudah selesai , bukan bera...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>meski masa kampanye sudah selesai , bukan bera...</td>\n",
       "      <td>0</td>\n",
       "      <td>monologis_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>tidak enak</td>\n",
       "      <td>negative</td>\n",
       "      <td>tidak enak</td>\n",
       "      <td>1</td>\n",
       "      <td>its_dul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>restoran ini menawarkan makanan sunda . kami m...</td>\n",
       "      <td>positive</td>\n",
       "      <td>restoran ini menawarkan makanan sunda . kami m...</td>\n",
       "      <td>2</td>\n",
       "      <td>meonkbaong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>lokasi di alun alun masakan padang ini cukup t...</td>\n",
       "      <td>positive</td>\n",
       "      <td>lokasi di alun alun masakan padang ini cukup t...</td>\n",
       "      <td>2</td>\n",
       "      <td>rakyatdotnews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>betapa bejad kader gerindra yang anggota dprd ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>betapa bejad kader gerindra yang anggota dprd ...</td>\n",
       "      <td>1</td>\n",
       "      <td>annisathalib_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>cinta pada pandangan pertama . perasaan itu la...</td>\n",
       "      <td>positive</td>\n",
       "      <td>cinta pada pandangan pertama . perasaan itu la...</td>\n",
       "      <td>2</td>\n",
       "      <td>gemawonorejo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>kebetulan lokasi nya dekat dengan tempat mengi...</td>\n",
       "      <td>positive</td>\n",
       "      <td>kebetulan lokasi nya dekat dengan tempat mengi...</td>\n",
       "      <td>2</td>\n",
       "      <td>covid_19chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>pan yakin punya modal jadi pilpres setelah men...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>pan yakin punya modal jadi pilpres setelah men...</td>\n",
       "      <td>0</td>\n",
       "      <td>sitiftmwti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>menu favorit ku di sini adalah pork neck , tap...</td>\n",
       "      <td>positive</td>\n",
       "      <td>menu favorit ku di sini adalah pork neck , tap...</td>\n",
       "      <td>2</td>\n",
       "      <td>freemasonryid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>paket winger kfc murah meriah dan enak</td>\n",
       "      <td>positive</td>\n",
       "      <td>paket winger kfc murah meriah dan enak</td>\n",
       "      <td>2</td>\n",
       "      <td>r_riil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                               text sentiment  \\\n",
       "0             0  meski masa kampanye sudah selesai , bukan bera...   neutral   \n",
       "1             1                                         tidak enak  negative   \n",
       "2             2  restoran ini menawarkan makanan sunda . kami m...  positive   \n",
       "3             3  lokasi di alun alun masakan padang ini cukup t...  positive   \n",
       "4             4  betapa bejad kader gerindra yang anggota dprd ...  negative   \n",
       "..          ...                                                ...       ...   \n",
       "995         995  cinta pada pandangan pertama . perasaan itu la...  positive   \n",
       "996         996  kebetulan lokasi nya dekat dengan tempat mengi...  positive   \n",
       "997         997  pan yakin punya modal jadi pilpres setelah men...   neutral   \n",
       "998         998  menu favorit ku di sini adalah pork neck , tap...  positive   \n",
       "999         999             paket winger kfc murah meriah dan enak  positive   \n",
       "\n",
       "                                            clean_text  label         username  \n",
       "0    meski masa kampanye sudah selesai , bukan bera...      0     monologis_id  \n",
       "1                                           tidak enak      1          its_dul  \n",
       "2    restoran ini menawarkan makanan sunda . kami m...      2       meonkbaong  \n",
       "3    lokasi di alun alun masakan padang ini cukup t...      2    rakyatdotnews  \n",
       "4    betapa bejad kader gerindra yang anggota dprd ...      1    annisathalib_  \n",
       "..                                                 ...    ...              ...  \n",
       "995  cinta pada pandangan pertama . perasaan itu la...      2     gemawonorejo  \n",
       "996  kebetulan lokasi nya dekat dengan tempat mengi...      2  covid_19chinese  \n",
       "997  pan yakin punya modal jadi pilpres setelah men...      0       sitiftmwti  \n",
       "998  menu favorit ku di sini adalah pork neck , tap...      2    freemasonryid  \n",
       "999             paket winger kfc murah meriah dan enak      2           r_riil  \n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23669b36-4a2d-4918-a332-34c31f99dc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0                                               text sentiment  \\\n",
      "0             0  meski masa kampanye sudah selesai , bukan bera...   neutral   \n",
      "1             1                                         tidak enak  negative   \n",
      "2             2  restoran ini menawarkan makanan sunda . kami m...  positive   \n",
      "3             3  lokasi di alun alun masakan padang ini cukup t...  positive   \n",
      "4             4  betapa bejad kader gerindra yang anggota dprd ...  negative   \n",
      "..          ...                                                ...       ...   \n",
      "995         995  cinta pada pandangan pertama . perasaan itu la...  positive   \n",
      "996         996  kebetulan lokasi nya dekat dengan tempat mengi...  positive   \n",
      "997         997  pan yakin punya modal jadi pilpres setelah men...   neutral   \n",
      "998         998  menu favorit ku di sini adalah pork neck , tap...  positive   \n",
      "999         999             paket winger kfc murah meriah dan enak  positive   \n",
      "\n",
      "                                            clean_text  label  \\\n",
      "0    meski masa kampanye sudah selesai , bukan bera...      0   \n",
      "1                                           tidak enak      1   \n",
      "2    restoran ini menawarkan makanan sunda . kami m...      2   \n",
      "3    lokasi di alun alun masakan padang ini cukup t...      2   \n",
      "4    betapa bejad kader gerindra yang anggota dprd ...      1   \n",
      "..                                                 ...    ...   \n",
      "995  cinta pada pandangan pertama . perasaan itu la...      2   \n",
      "996  kebetulan lokasi nya dekat dengan tempat mengi...      2   \n",
      "997  pan yakin punya modal jadi pilpres setelah men...      0   \n",
      "998  menu favorit ku di sini adalah pork neck , tap...      2   \n",
      "999             paket winger kfc murah meriah dan enak      2   \n",
      "\n",
      "            username       date  \n",
      "0       monologis_id 2023-02-15  \n",
      "1            its_dul 2023-12-27  \n",
      "2         meonkbaong 2023-10-29  \n",
      "3      rakyatdotnews 2023-04-12  \n",
      "4      annisathalib_ 2023-10-02  \n",
      "..               ...        ...  \n",
      "995     gemawonorejo 2023-05-28  \n",
      "996  covid_19chinese 2023-08-15  \n",
      "997       sitiftmwti 2023-08-14  \n",
      "998    freemasonryid 2023-06-10  \n",
      "999           r_riil 2023-03-12  \n",
      "\n",
      "[1000 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def insert_random_dates(start_date, end_date, n):\n",
    "    \"\"\"\n",
    "    Generates n random dates between start_date and end_date.\n",
    "    \n",
    "    Args:\n",
    "        start_date (str or pd.Timestamp): The beginning of the date range.\n",
    "        end_date (str or pd.Timestamp): The end of the date range.\n",
    "        n (int): The number of random dates to generate.\n",
    "        \n",
    "    Returns:\n",
    "        pd.Series: A pandas Series containing random datetime objects.\n",
    "    \"\"\"\n",
    "    # Convert string dates to pandas Timestamp objects\n",
    "    start = pd.to_datetime(start_date)\n",
    "    end = pd.to_datetime(end_date)\n",
    "    \n",
    "    # Calculate the total number of days in the range\n",
    "    ndays = (end - start).days + 1\n",
    "    \n",
    "    # Generate 'n' random integers representing days within the range\n",
    "    random_days = np.random.randint(0, ndays, n)\n",
    "    \n",
    "    # Add these random days as a timedelta to the start date\n",
    "    random_dates = start + pd.to_timedelta(random_days, unit='D')\n",
    "    \n",
    "    return pd.Series(random_dates)\n",
    "\n",
    "# --- Example Usage ---\n",
    "df4 = pd.DataFrame({'value': np.random.randn(1000)}) # Example DataFrame with 10 rows\n",
    "start_date_str = '2023-01-01'\n",
    "end_date_str = '2024-01-01'\n",
    "\n",
    "df['date'] = insert_random_dates(start_date_str, end_date_str, len(df))\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cdb623a-b2f6-4993-866e-cedefffc92c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "text          0\n",
       "sentiment     0\n",
       "clean_text    0\n",
       "label         0\n",
       "username      0\n",
       "date          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39f844be-5f14-4563-8f2a-158ef18550ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('demo_data_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee410d90-a87b-43c7-8d3c-e382492ff31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.751818</td>\n",
       "      <td>2023-06-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.787613</td>\n",
       "      <td>2023-07-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.446962</td>\n",
       "      <td>2023-12-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.711865</td>\n",
       "      <td>2023-10-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.543799</td>\n",
       "      <td>2023-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.535128</td>\n",
       "      <td>2023-08-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.269073</td>\n",
       "      <td>2023-08-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.712783</td>\n",
       "      <td>2023-06-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.374961</td>\n",
       "      <td>2023-08-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.485872</td>\n",
       "      <td>2023-09-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      value       date\n",
       "0  0.751818 2023-06-12\n",
       "1 -0.787613 2023-07-19\n",
       "2  0.446962 2023-12-23\n",
       "3 -0.711865 2023-10-13\n",
       "4  1.543799 2023-05-26\n",
       "5 -0.535128 2023-08-24\n",
       "6 -1.269073 2023-08-05\n",
       "7 -1.712783 2023-06-03\n",
       "8  1.374961 2023-08-16\n",
       "9 -0.485872 2023-09-28"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05430fca-6819-4f87-b149-3934af94e6c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>label</th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>meski masa kampanye sudah selesai , bukan bera...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>meski masa kampanye sudah selesai , bukan bera...</td>\n",
       "      <td>0</td>\n",
       "      <td>monologis_id</td>\n",
       "      <td>2020-05-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>tidak enak</td>\n",
       "      <td>negative</td>\n",
       "      <td>tidak enak</td>\n",
       "      <td>1</td>\n",
       "      <td>its_dul</td>\n",
       "      <td>2020-05-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>restoran ini menawarkan makanan sunda . kami m...</td>\n",
       "      <td>positive</td>\n",
       "      <td>restoran ini menawarkan makanan sunda . kami m...</td>\n",
       "      <td>2</td>\n",
       "      <td>meonkbaong</td>\n",
       "      <td>2020-05-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>lokasi di alun alun masakan padang ini cukup t...</td>\n",
       "      <td>positive</td>\n",
       "      <td>lokasi di alun alun masakan padang ini cukup t...</td>\n",
       "      <td>2</td>\n",
       "      <td>rakyatdotnews</td>\n",
       "      <td>2020-05-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>betapa bejad kader gerindra yang anggota dprd ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>betapa bejad kader gerindra yang anggota dprd ...</td>\n",
       "      <td>1</td>\n",
       "      <td>annisathalib_</td>\n",
       "      <td>2020-05-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>cinta pada pandangan pertama . perasaan itu la...</td>\n",
       "      <td>positive</td>\n",
       "      <td>cinta pada pandangan pertama . perasaan itu la...</td>\n",
       "      <td>2</td>\n",
       "      <td>gemawonorejo</td>\n",
       "      <td>2020-05-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>kebetulan lokasi nya dekat dengan tempat mengi...</td>\n",
       "      <td>positive</td>\n",
       "      <td>kebetulan lokasi nya dekat dengan tempat mengi...</td>\n",
       "      <td>2</td>\n",
       "      <td>covid_19chinese</td>\n",
       "      <td>2020-05-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>pan yakin punya modal jadi pilpres setelah men...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>pan yakin punya modal jadi pilpres setelah men...</td>\n",
       "      <td>0</td>\n",
       "      <td>sitiftmwti</td>\n",
       "      <td>2020-05-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>menu favorit ku di sini adalah pork neck , tap...</td>\n",
       "      <td>positive</td>\n",
       "      <td>menu favorit ku di sini adalah pork neck , tap...</td>\n",
       "      <td>2</td>\n",
       "      <td>freemasonryid</td>\n",
       "      <td>2020-05-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>paket winger kfc murah meriah dan enak</td>\n",
       "      <td>positive</td>\n",
       "      <td>paket winger kfc murah meriah dan enak</td>\n",
       "      <td>2</td>\n",
       "      <td>r_riil</td>\n",
       "      <td>2020-05-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                               text sentiment  \\\n",
       "0             0  meski masa kampanye sudah selesai , bukan bera...   neutral   \n",
       "1             1                                         tidak enak  negative   \n",
       "2             2  restoran ini menawarkan makanan sunda . kami m...  positive   \n",
       "3             3  lokasi di alun alun masakan padang ini cukup t...  positive   \n",
       "4             4  betapa bejad kader gerindra yang anggota dprd ...  negative   \n",
       "..          ...                                                ...       ...   \n",
       "995         995  cinta pada pandangan pertama . perasaan itu la...  positive   \n",
       "996         996  kebetulan lokasi nya dekat dengan tempat mengi...  positive   \n",
       "997         997  pan yakin punya modal jadi pilpres setelah men...   neutral   \n",
       "998         998  menu favorit ku di sini adalah pork neck , tap...  positive   \n",
       "999         999             paket winger kfc murah meriah dan enak  positive   \n",
       "\n",
       "                                            clean_text  label  \\\n",
       "0    meski masa kampanye sudah selesai , bukan bera...      0   \n",
       "1                                           tidak enak      1   \n",
       "2    restoran ini menawarkan makanan sunda . kami m...      2   \n",
       "3    lokasi di alun alun masakan padang ini cukup t...      2   \n",
       "4    betapa bejad kader gerindra yang anggota dprd ...      1   \n",
       "..                                                 ...    ...   \n",
       "995  cinta pada pandangan pertama . perasaan itu la...      2   \n",
       "996  kebetulan lokasi nya dekat dengan tempat mengi...      2   \n",
       "997  pan yakin punya modal jadi pilpres setelah men...      0   \n",
       "998  menu favorit ku di sini adalah pork neck , tap...      2   \n",
       "999             paket winger kfc murah meriah dan enak      2   \n",
       "\n",
       "            username       date  \n",
       "0       monologis_id 2020-05-07  \n",
       "1            its_dul 2020-05-07  \n",
       "2         meonkbaong 2020-05-07  \n",
       "3      rakyatdotnews 2020-05-07  \n",
       "4      annisathalib_ 2020-05-07  \n",
       "..               ...        ...  \n",
       "995     gemawonorejo 2020-05-07  \n",
       "996  covid_19chinese 2020-05-07  \n",
       "997       sitiftmwti 2020-05-07  \n",
       "998    freemasonryid 2020-05-07  \n",
       "999           r_riil 2020-05-07  \n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = df.iloc[:1000]\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8bf89d-5502-4f6c-b366-ba817d56c295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99a0eb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0124627f-7197-4870-ae7f-537ac828627b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Abdullah Ghassan\\\\env - semester 5\\\\softeng'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45db9938-5278-40b1-888c-83e550cd13f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n",
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/alvinhanafie/dataset-for-indonesian-sentiment-analysis?dataset_version_number=4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 860k/860k [00:01<00:00, 615kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n",
      "Path to dataset files: C:\\Users\\Abdullah Ghassan\\.cache\\kagglehub\\datasets\\alvinhanafie\\dataset-for-indonesian-sentiment-analysis\\versions\\4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"alvinhanafie/dataset-for-indonesian-sentiment-analysis\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc649c80-fd11-4887-be66-3a49f3c34a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_preprocess_ori.tsv', sep = '\\t')\n",
    "test = pd.read_csv('valid_preprocess.tsv', sep = '\\t')\n",
    "val = pd.read_csv('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b6d6d82-07c2-455d-a213-05f4e68d4cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warung ini dimiliki oleh pengusaha pabrik tahu...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mohon ulama lurus dan k212 mmbri hujjah partai...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lokasi strategis di jalan sumatera bandung . t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>betapa bahagia nya diri ini saat unboxing pake...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>duh . jadi mahasiswa jangan sombong dong . kas...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10995</th>\n",
       "      <td>tidak kecewa</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10996</th>\n",
       "      <td>enak rasa masakan nya apalagi kepiting yang me...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10997</th>\n",
       "      <td>hormati partai-partai yang telah berkoalisi</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10998</th>\n",
       "      <td>pagi pagi di tol pasteur sudah macet parah , b...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999</th>\n",
       "      <td>meskipun sering belanja ke yogya di riau junct...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text sentiment\n",
       "0      warung ini dimiliki oleh pengusaha pabrik tahu...  positive\n",
       "1      mohon ulama lurus dan k212 mmbri hujjah partai...   neutral\n",
       "2      lokasi strategis di jalan sumatera bandung . t...  positive\n",
       "3      betapa bahagia nya diri ini saat unboxing pake...  positive\n",
       "4      duh . jadi mahasiswa jangan sombong dong . kas...  negative\n",
       "...                                                  ...       ...\n",
       "10995                                       tidak kecewa  positive\n",
       "10996  enak rasa masakan nya apalagi kepiting yang me...  positive\n",
       "10997        hormati partai-partai yang telah berkoalisi   neutral\n",
       "10998  pagi pagi di tol pasteur sudah macet parah , b...  negative\n",
       "10999  meskipun sering belanja ke yogya di riau junct...  positive\n",
       "\n",
       "[11000 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad974c11-9975-4d3b-8403-16510ba25eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>meski masa kampanye sudah selesai , bukan bera...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tidak enak</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>restoran ini menawarkan makanan sunda . kami m...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lokasi di alun alun masakan padang ini cukup t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>betapa bejad kader gerindra yang anggota dprd ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>film tncfu , tidak cocok untuk penonton yang t...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>indihome ini mahal loh bayar nya . hanya , pen...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>be de gea , cowok cupu yang takut dengan pacar...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>valen yang sangat tidak berkualitas . konentat...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>restoran ini menjadi tempat pilihan saya berbu...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1260 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text sentiment\n",
       "0     meski masa kampanye sudah selesai , bukan bera...   neutral\n",
       "1                                            tidak enak  negative\n",
       "2     restoran ini menawarkan makanan sunda . kami m...  positive\n",
       "3     lokasi di alun alun masakan padang ini cukup t...  positive\n",
       "4     betapa bejad kader gerindra yang anggota dprd ...  negative\n",
       "...                                                 ...       ...\n",
       "1255  film tncfu , tidak cocok untuk penonton yang t...  negative\n",
       "1256  indihome ini mahal loh bayar nya . hanya , pen...  negative\n",
       "1257  be de gea , cowok cupu yang takut dengan pacar...  negative\n",
       "1258  valen yang sangat tidak berkualitas . konentat...  negative\n",
       "1259  restoran ini menjadi tempat pilihan saya berbu...  positive\n",
       "\n",
       "[1260 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a9dbd48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warung ini dimiliki oleh pengusaha pabrik tahu...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mohon ulama lurus dan k212 mmbri hujjah partai...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lokasi strategis di jalan sumatera bandung . t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>betapa bahagia nya diri ini saat unboxing pake...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>duh . jadi mahasiswa jangan sombong dong . kas...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>makanan beragam , harga makanan di food stall ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pakai kartu kredit bca tidak untung malah rugi...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tempat unik , bagus buat foto , makanan enak ,...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>saya bersama keluarga baru saja menikmati peng...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bersyukur</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>simcard indosat inaktiv gara-gara lupa isi pul...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sifat iri sering muncul pada orang orang yang ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sekadar menceritakan pengalaman saya pesan ste...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pengalaman bersama indosat hari ini , semoga t...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>anak sekarang sulit untuk dinasehati</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hanya mengatasi masalah kayak gini saja anies ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>setiap bumn dibentuk dengan uu bukan dibentuk ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sehabis puas bermain di trans studio bandung ,...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rasa bakso cuanki dan batagor cukup . selalu r...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sgwr 2018 beri dampak positif terhadap hobi an...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>berada di lembang , pemandangan indah , udara ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>berbuka puasa di sini pada minggu lepas , pak ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>hahaha suka banget nonton kartun indonesia kel...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>bagi teman-teman yang sedang berkunjung ke ban...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>di restoran ini , saya dan keluarga makan mala...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>alhamdulillah hari ini tidak ke jalan bugel ag...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>respon agak lama , sama sayang nya rem nya buk...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>lokasi dengan pemandangan alam yang masih natu...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>pdip sebut ridwan kamil menang karena berbaju ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>malu - maluin nih oknum yang tidak bertanggung...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>makan siang di sini asyik juga . nuansa bali w...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>tempat steak di bandung sejak lama dari zaman ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>08:30 : kedatangan presiden ri dan rombongan d...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>makanan tradisional yang selalu rasanya stabil...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>sampai saat ini saya rasa batagor ini masih ya...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>aroma khas yang ada jika makan di atas daun pi...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>akhir tahun lalu saya dan keluarga berjalan ke...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>risma menjatuhkan pilihan nya pada gus ipul - ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>pengalaman yang cukup seru , makan tanpa alas ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>makanan nya enak , suasana nyaman . harga bisa...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>kampung daun adalah tempat makan yang menyatuk...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>waktu itu ke sini pesan nasi goreng dan kentan...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>banyak sekali tempat makan sunda yang bertebar...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>hai tolong bantu saya tidak bisa input tidak r...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>foods : menu baru cheeseburger nya oke banget ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>dusun bambu ini tergolong baru di bandung . te...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>tidak memuaskan</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>suruh ngaca pemain nya ! dasar oneng ! ngomong...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>kafe ini menyajikan sensasi makan dalam gelap ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>sesuai dengan nama nya mi awie , kedai makan i...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text sentiment\n",
       "0   warung ini dimiliki oleh pengusaha pabrik tahu...  positive\n",
       "1   mohon ulama lurus dan k212 mmbri hujjah partai...   neutral\n",
       "2   lokasi strategis di jalan sumatera bandung . t...  positive\n",
       "3   betapa bahagia nya diri ini saat unboxing pake...  positive\n",
       "4   duh . jadi mahasiswa jangan sombong dong . kas...  negative\n",
       "5   makanan beragam , harga makanan di food stall ...  positive\n",
       "6   pakai kartu kredit bca tidak untung malah rugi...  negative\n",
       "7   tempat unik , bagus buat foto , makanan enak ,...  positive\n",
       "8   saya bersama keluarga baru saja menikmati peng...  positive\n",
       "9                                           bersyukur  positive\n",
       "10  simcard indosat inaktiv gara-gara lupa isi pul...  negative\n",
       "11  sifat iri sering muncul pada orang orang yang ...  negative\n",
       "12  sekadar menceritakan pengalaman saya pesan ste...  positive\n",
       "13  pengalaman bersama indosat hari ini , semoga t...  negative\n",
       "14               anak sekarang sulit untuk dinasehati  negative\n",
       "15  hanya mengatasi masalah kayak gini saja anies ...  negative\n",
       "16  setiap bumn dibentuk dengan uu bukan dibentuk ...   neutral\n",
       "17  sehabis puas bermain di trans studio bandung ,...  positive\n",
       "18  rasa bakso cuanki dan batagor cukup . selalu r...  positive\n",
       "19  sgwr 2018 beri dampak positif terhadap hobi an...  positive\n",
       "20  berada di lembang , pemandangan indah , udara ...  positive\n",
       "21  berbuka puasa di sini pada minggu lepas , pak ...  positive\n",
       "22  hahaha suka banget nonton kartun indonesia kel...  positive\n",
       "23  bagi teman-teman yang sedang berkunjung ke ban...  positive\n",
       "24  di restoran ini , saya dan keluarga makan mala...  positive\n",
       "25  alhamdulillah hari ini tidak ke jalan bugel ag...  negative\n",
       "26  respon agak lama , sama sayang nya rem nya buk...  negative\n",
       "27  lokasi dengan pemandangan alam yang masih natu...  positive\n",
       "28  pdip sebut ridwan kamil menang karena berbaju ...   neutral\n",
       "29  malu - maluin nih oknum yang tidak bertanggung...  negative\n",
       "30  makan siang di sini asyik juga . nuansa bali w...  negative\n",
       "31  tempat steak di bandung sejak lama dari zaman ...  positive\n",
       "32  08:30 : kedatangan presiden ri dan rombongan d...   neutral\n",
       "33  makanan tradisional yang selalu rasanya stabil...  positive\n",
       "34  sampai saat ini saya rasa batagor ini masih ya...  positive\n",
       "35  aroma khas yang ada jika makan di atas daun pi...  positive\n",
       "36  akhir tahun lalu saya dan keluarga berjalan ke...  positive\n",
       "37  risma menjatuhkan pilihan nya pada gus ipul - ...   neutral\n",
       "38  pengalaman yang cukup seru , makan tanpa alas ...  positive\n",
       "39  makanan nya enak , suasana nyaman . harga bisa...  positive\n",
       "40  kampung daun adalah tempat makan yang menyatuk...  positive\n",
       "41  waktu itu ke sini pesan nasi goreng dan kentan...  positive\n",
       "42  banyak sekali tempat makan sunda yang bertebar...  positive\n",
       "43  hai tolong bantu saya tidak bisa input tidak r...   neutral\n",
       "44  foods : menu baru cheeseburger nya oke banget ...  positive\n",
       "45  dusun bambu ini tergolong baru di bandung . te...  positive\n",
       "46                                    tidak memuaskan  negative\n",
       "47  suruh ngaca pemain nya ! dasar oneng ! ngomong...  negative\n",
       "48  kafe ini menyajikan sensasi makan dalam gelap ...  negative\n",
       "49  sesuai dengan nama nya mi awie , kedai makan i...  positive"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80ef101",
   "metadata": {},
   "source": [
    "# **Model 1: modernBERT**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3136a28c",
   "metadata": {},
   "source": [
    "## Preprocessing for BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afd170a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def specialized_cleaning(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "\n",
    "    # Hapus bagian \"Nb: ...\"\n",
    "    text = re.sub(r'nb:.*', '', text)\n",
    "    \n",
    "    # Normalisasi karakter berulang (\"sakiitttt\" -> \"sakit\")\n",
    "    text = re.sub(r'(.)\\1{2,}', r'\\1', text)\n",
    "    \n",
    "    # Ganti baris baru dengan spasi\n",
    "    text = text.replace('\\n', ' ')\n",
    "    \n",
    "    # Kamus Slang\n",
    "    slang_dict = {\n",
    "        r'\\buu\\b': 'undang undang',\n",
    "        r'\\bga\\b': 'tidak',\n",
    "        r'\\bgak\\b': 'tidak',\n",
    "        r'\\bgw\\b': 'aku', \n",
    "        r'\\bkrn\\b': 'karena',\n",
    "        r'\\bkalo\\b': 'kalau',\n",
    "        r'\\bkl\\b': 'kalau', \n",
    "        r'\\btdk\\b': 'tidak',\n",
    "        r'\\bsy\\b': 'saya',\n",
    "        r'\\bpie\\b': 'bagaimana', \n",
    "        r'\\bbgt\\b': 'banget',\n",
    "        r'\\bdgn\\b': 'dengan',\n",
    "        r'\\biki\\b': 'ini', \n",
    "        r'\\bsdh\\b': 'sudah', \n",
    "        r'\\baja\\b': 'saja',\n",
    "        r'\\btrus\\b': 'terus', \n",
    "        r'\\bsm\\b': 'sama',\n",
    "        r'\\bdtg\\b': 'datang',\n",
    "        r'\\bbgmn\\b' : 'bagaimana',\n",
    "        r'\\bgimana\\b' : 'bagaimana',\n",
    "         r'\\bbyk\\b' : 'banyak',\n",
    "         r'\\bbodo amat\\b' : 'tidak peduli',\n",
    "         r'\\btuh\\b' : 'itu',\n",
    "         r'\\bngaca\\b' : 'intropeksi',\n",
    "        r'\\bmmbri\\b' : 'memberi'\n",
    "        \n",
    "    }\n",
    "    for pattern, replacement in slang_dict.items():\n",
    "        text = re.sub(pattern, replacement, text)\n",
    "        \n",
    "    # HAPUS EMOJI & Simbol Aneh (Hanya sisakan huruf, angka, spasi, .,!?)\n",
    "    text = re.sub(r'[^a-z0-9\\s.,!?]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b29d92a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warung ini dimiliki oleh pengusaha pabrik tahu...</td>\n",
       "      <td>warung ini dimiliki oleh pengusaha pabrik tahu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mohon ulama lurus dan k212 mmbri hujjah partai...</td>\n",
       "      <td>mohon ulama lurus dan k212 memberi hujjah part...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lokasi strategis di jalan sumatera bandung . t...</td>\n",
       "      <td>lokasi strategis di jalan sumatera bandung . t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>betapa bahagia nya diri ini saat unboxing pake...</td>\n",
       "      <td>betapa bahagia nya diri ini saat unboxing pake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>duh . jadi mahasiswa jangan sombong dong . kas...</td>\n",
       "      <td>duh . jadi mahasiswa jangan sombong dong . kas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>makanan beragam , harga makanan di food stall ...</td>\n",
       "      <td>makanan beragam , harga makanan di food stall ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pakai kartu kredit bca tidak untung malah rugi...</td>\n",
       "      <td>pakai kartu kredit bca tidak untung malah rugi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tempat unik , bagus buat foto , makanan enak ,...</td>\n",
       "      <td>tempat unik , bagus buat foto , makanan enak ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>saya bersama keluarga baru saja menikmati peng...</td>\n",
       "      <td>saya bersama keluarga baru saja menikmati peng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bersyukur</td>\n",
       "      <td>bersyukur</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  warung ini dimiliki oleh pengusaha pabrik tahu...   \n",
       "1  mohon ulama lurus dan k212 mmbri hujjah partai...   \n",
       "2  lokasi strategis di jalan sumatera bandung . t...   \n",
       "3  betapa bahagia nya diri ini saat unboxing pake...   \n",
       "4  duh . jadi mahasiswa jangan sombong dong . kas...   \n",
       "5  makanan beragam , harga makanan di food stall ...   \n",
       "6  pakai kartu kredit bca tidak untung malah rugi...   \n",
       "7  tempat unik , bagus buat foto , makanan enak ,...   \n",
       "8  saya bersama keluarga baru saja menikmati peng...   \n",
       "9                                          bersyukur   \n",
       "\n",
       "                                          clean_text  \n",
       "0  warung ini dimiliki oleh pengusaha pabrik tahu...  \n",
       "1  mohon ulama lurus dan k212 memberi hujjah part...  \n",
       "2  lokasi strategis di jalan sumatera bandung . t...  \n",
       "3  betapa bahagia nya diri ini saat unboxing pake...  \n",
       "4  duh . jadi mahasiswa jangan sombong dong . kas...  \n",
       "5  makanan beragam , harga makanan di food stall ...  \n",
       "6  pakai kartu kredit bca tidak untung malah rugi...  \n",
       "7  tempat unik , bagus buat foto , makanan enak ,...  \n",
       "8  saya bersama keluarga baru saja menikmati peng...  \n",
       "9                                          bersyukur  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['clean_text'] = train['text'].apply(specialized_cleaning)\n",
    "train[['text', 'clean_text']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6aa3f65-0ab2-483f-9f6b-ba4ee839f72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['clean_text'] = test['text'].apply(specialized_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31f498aa-dfac-46fd-9b3e-21a1efc9a243",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {'positive' : 2, 'negative' : 1 , 'neutral' : 0}\n",
    "\n",
    "train['label'] = train['sentiment'].map(label_dict)\n",
    "test['label'] = test['sentiment'].map(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aaa8be9e-abfe-45cc-86d6-52a03f49aec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warung ini dimiliki oleh pengusaha pabrik tahu...</td>\n",
       "      <td>positive</td>\n",
       "      <td>warung ini dimiliki oleh pengusaha pabrik tahu...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mohon ulama lurus dan k212 mmbri hujjah partai...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>mohon ulama lurus dan k212 memberi hujjah part...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lokasi strategis di jalan sumatera bandung . t...</td>\n",
       "      <td>positive</td>\n",
       "      <td>lokasi strategis di jalan sumatera bandung . t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>betapa bahagia nya diri ini saat unboxing pake...</td>\n",
       "      <td>positive</td>\n",
       "      <td>betapa bahagia nya diri ini saat unboxing pake...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>duh . jadi mahasiswa jangan sombong dong . kas...</td>\n",
       "      <td>negative</td>\n",
       "      <td>duh . jadi mahasiswa jangan sombong dong . kas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10995</th>\n",
       "      <td>tidak kecewa</td>\n",
       "      <td>positive</td>\n",
       "      <td>tidak kecewa</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10996</th>\n",
       "      <td>enak rasa masakan nya apalagi kepiting yang me...</td>\n",
       "      <td>positive</td>\n",
       "      <td>enak rasa masakan nya apalagi kepiting yang me...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10997</th>\n",
       "      <td>hormati partai-partai yang telah berkoalisi</td>\n",
       "      <td>neutral</td>\n",
       "      <td>hormati partaipartai yang telah berkoalisi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10998</th>\n",
       "      <td>pagi pagi di tol pasteur sudah macet parah , b...</td>\n",
       "      <td>negative</td>\n",
       "      <td>pagi pagi di tol pasteur sudah macet parah , b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999</th>\n",
       "      <td>meskipun sering belanja ke yogya di riau junct...</td>\n",
       "      <td>positive</td>\n",
       "      <td>meskipun sering belanja ke yogya di riau junct...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text sentiment  \\\n",
       "0      warung ini dimiliki oleh pengusaha pabrik tahu...  positive   \n",
       "1      mohon ulama lurus dan k212 mmbri hujjah partai...   neutral   \n",
       "2      lokasi strategis di jalan sumatera bandung . t...  positive   \n",
       "3      betapa bahagia nya diri ini saat unboxing pake...  positive   \n",
       "4      duh . jadi mahasiswa jangan sombong dong . kas...  negative   \n",
       "...                                                  ...       ...   \n",
       "10995                                       tidak kecewa  positive   \n",
       "10996  enak rasa masakan nya apalagi kepiting yang me...  positive   \n",
       "10997        hormati partai-partai yang telah berkoalisi   neutral   \n",
       "10998  pagi pagi di tol pasteur sudah macet parah , b...  negative   \n",
       "10999  meskipun sering belanja ke yogya di riau junct...  positive   \n",
       "\n",
       "                                              clean_text  label  \n",
       "0      warung ini dimiliki oleh pengusaha pabrik tahu...      2  \n",
       "1      mohon ulama lurus dan k212 memberi hujjah part...      0  \n",
       "2      lokasi strategis di jalan sumatera bandung . t...      2  \n",
       "3      betapa bahagia nya diri ini saat unboxing pake...      2  \n",
       "4      duh . jadi mahasiswa jangan sombong dong . kas...      1  \n",
       "...                                                  ...    ...  \n",
       "10995                                       tidak kecewa      2  \n",
       "10996  enak rasa masakan nya apalagi kepiting yang me...      2  \n",
       "10997         hormati partaipartai yang telah berkoalisi      0  \n",
       "10998  pagi pagi di tol pasteur sudah macet parah , b...      1  \n",
       "10999  meskipun sering belanja ke yogya di riau junct...      2  \n",
       "\n",
       "[11000 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d22fd00-b8bc-4459-a21e-c55d8454559d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>meski masa kampanye sudah selesai , bukan bera...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>meski masa kampanye sudah selesai , bukan bera...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tidak enak</td>\n",
       "      <td>negative</td>\n",
       "      <td>tidak enak</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>restoran ini menawarkan makanan sunda . kami m...</td>\n",
       "      <td>positive</td>\n",
       "      <td>restoran ini menawarkan makanan sunda . kami m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lokasi di alun alun masakan padang ini cukup t...</td>\n",
       "      <td>positive</td>\n",
       "      <td>lokasi di alun alun masakan padang ini cukup t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>betapa bejad kader gerindra yang anggota dprd ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>betapa bejad kader gerindra yang anggota dprd ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>film tncfu , tidak cocok untuk penonton yang t...</td>\n",
       "      <td>negative</td>\n",
       "      <td>film tncfu , tidak cocok untuk penonton yang t...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>indihome ini mahal loh bayar nya . hanya , pen...</td>\n",
       "      <td>negative</td>\n",
       "      <td>indihome ini mahal loh bayar nya . hanya , pen...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>be de gea , cowok cupu yang takut dengan pacar...</td>\n",
       "      <td>negative</td>\n",
       "      <td>be de gea , cowok cupu yang takut dengan pacar...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>valen yang sangat tidak berkualitas . konentat...</td>\n",
       "      <td>negative</td>\n",
       "      <td>valen yang sangat tidak berkualitas . konentat...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>restoran ini menjadi tempat pilihan saya berbu...</td>\n",
       "      <td>positive</td>\n",
       "      <td>restoran ini menjadi tempat pilihan saya berbu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1260 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text sentiment  \\\n",
       "0     meski masa kampanye sudah selesai , bukan bera...   neutral   \n",
       "1                                            tidak enak  negative   \n",
       "2     restoran ini menawarkan makanan sunda . kami m...  positive   \n",
       "3     lokasi di alun alun masakan padang ini cukup t...  positive   \n",
       "4     betapa bejad kader gerindra yang anggota dprd ...  negative   \n",
       "...                                                 ...       ...   \n",
       "1255  film tncfu , tidak cocok untuk penonton yang t...  negative   \n",
       "1256  indihome ini mahal loh bayar nya . hanya , pen...  negative   \n",
       "1257  be de gea , cowok cupu yang takut dengan pacar...  negative   \n",
       "1258  valen yang sangat tidak berkualitas . konentat...  negative   \n",
       "1259  restoran ini menjadi tempat pilihan saya berbu...  positive   \n",
       "\n",
       "                                             clean_text  label  \n",
       "0     meski masa kampanye sudah selesai , bukan bera...      0  \n",
       "1                                            tidak enak     -1  \n",
       "2     restoran ini menawarkan makanan sunda . kami m...      1  \n",
       "3     lokasi di alun alun masakan padang ini cukup t...      1  \n",
       "4     betapa bejad kader gerindra yang anggota dprd ...     -1  \n",
       "...                                                 ...    ...  \n",
       "1255  film tncfu , tidak cocok untuk penonton yang t...     -1  \n",
       "1256  indihome ini mahal loh bayar nya . hanya , pen...     -1  \n",
       "1257  be de gea , cowok cupu yang takut dengan pacar...     -1  \n",
       "1258  valen yang sangat tidak berkualitas . konentat...     -1  \n",
       "1259  restoran ini menjadi tempat pilihan saya berbu...      1  \n",
       "\n",
       "[1260 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e02ef96d-9b10-41e2-8757-0f5ecca27284",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('demo_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "264063a3-21fa-46c4-9cd4-18f1dd4cdc2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['softeng.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump((train, test), 'softeng.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92f9864a-4068-42c2-bacf-2b177b10b872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['softeng.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump((train, test), 'softeng.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c862394",
   "metadata": {},
   "source": [
    "Preprocessing BERT masih simpan tanda baca, supaya menangkap konteks kalimat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71d1a925-5bbb-4b8c-b6c7-ba1cbacc7bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['clean_text']\n",
    "y_train = train['label']\n",
    "X_temp = test['clean_text']\n",
    "y_temp = test['label']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=2/3, random_state=42, stratify=y_temp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2f40b20-f9a0-4967-a837-3a3df81e0a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"answerdotai/ModernBERT-base\",\n",
    "    cache_dir=r'C:\\Users\\Abdullah Ghassan\\.cache\\huggingface\\hub'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7da41a83-83c9-4e2e-b2b2-840d9e29ebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"FacebookAI/roberta-base\", cache_dir = r'C:\\Users\\Abdullah Ghassan\\.cache\\huggingface\\hub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aefa1cc6-a8c5-44ce-b0eb-d72a5fc6e2c2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='answerdotai/ModernBERT-base', vocab_size=50280, model_max_length=8192, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
       "\t0: AddedToken(\"|||IP_ADDRESS|||\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t1: AddedToken(\"<|padding|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t50254: AddedToken(\"                        \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50255: AddedToken(\"                       \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50256: AddedToken(\"                      \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50257: AddedToken(\"                     \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50258: AddedToken(\"                    \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50259: AddedToken(\"                   \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50260: AddedToken(\"                  \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50261: AddedToken(\"                 \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50262: AddedToken(\"                \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50263: AddedToken(\"               \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50264: AddedToken(\"              \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50265: AddedToken(\"             \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50266: AddedToken(\"            \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50267: AddedToken(\"           \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50268: AddedToken(\"          \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50269: AddedToken(\"         \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50270: AddedToken(\"        \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50271: AddedToken(\"       \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50272: AddedToken(\"      \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50273: AddedToken(\"     \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50274: AddedToken(\"    \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50275: AddedToken(\"   \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50276: AddedToken(\"  \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50277: AddedToken(\"|||EMAIL_ADDRESS|||\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50278: AddedToken(\"|||PHONE_NUMBER|||\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50279: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t50280: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t50281: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t50282: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t50283: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t50284: AddedToken(\"[MASK]\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),\n",
       "\t50285: AddedToken(\"[unused0]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50286: AddedToken(\"[unused1]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50287: AddedToken(\"[unused2]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50288: AddedToken(\"[unused3]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50289: AddedToken(\"[unused4]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50290: AddedToken(\"[unused5]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50291: AddedToken(\"[unused6]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50292: AddedToken(\"[unused7]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50293: AddedToken(\"[unused8]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50294: AddedToken(\"[unused9]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50295: AddedToken(\"[unused10]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50296: AddedToken(\"[unused11]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50297: AddedToken(\"[unused12]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50298: AddedToken(\"[unused13]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50299: AddedToken(\"[unused14]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50300: AddedToken(\"[unused15]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50301: AddedToken(\"[unused16]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50302: AddedToken(\"[unused17]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50303: AddedToken(\"[unused18]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50304: AddedToken(\"[unused19]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50305: AddedToken(\"[unused20]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50306: AddedToken(\"[unused21]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50307: AddedToken(\"[unused22]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50308: AddedToken(\"[unused23]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50309: AddedToken(\"[unused24]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50310: AddedToken(\"[unused25]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50311: AddedToken(\"[unused26]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50312: AddedToken(\"[unused27]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50313: AddedToken(\"[unused28]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50314: AddedToken(\"[unused29]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50315: AddedToken(\"[unused30]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50316: AddedToken(\"[unused31]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50317: AddedToken(\"[unused32]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50318: AddedToken(\"[unused33]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50319: AddedToken(\"[unused34]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50320: AddedToken(\"[unused35]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50321: AddedToken(\"[unused36]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50322: AddedToken(\"[unused37]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50323: AddedToken(\"[unused38]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50324: AddedToken(\"[unused39]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50325: AddedToken(\"[unused40]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50326: AddedToken(\"[unused41]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50327: AddedToken(\"[unused42]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50328: AddedToken(\"[unused43]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50329: AddedToken(\"[unused44]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50330: AddedToken(\"[unused45]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50331: AddedToken(\"[unused46]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50332: AddedToken(\"[unused47]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50333: AddedToken(\"[unused48]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50334: AddedToken(\"[unused49]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50335: AddedToken(\"[unused50]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50336: AddedToken(\"[unused51]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50337: AddedToken(\"[unused52]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50338: AddedToken(\"[unused53]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50339: AddedToken(\"[unused54]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50340: AddedToken(\"[unused55]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50341: AddedToken(\"[unused56]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50342: AddedToken(\"[unused57]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50343: AddedToken(\"[unused58]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50344: AddedToken(\"[unused59]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50345: AddedToken(\"[unused60]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50346: AddedToken(\"[unused61]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50347: AddedToken(\"[unused62]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50348: AddedToken(\"[unused63]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50349: AddedToken(\"[unused64]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50350: AddedToken(\"[unused65]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50351: AddedToken(\"[unused66]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50352: AddedToken(\"[unused67]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50353: AddedToken(\"[unused68]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50354: AddedToken(\"[unused69]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50355: AddedToken(\"[unused70]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50356: AddedToken(\"[unused71]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50357: AddedToken(\"[unused72]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50358: AddedToken(\"[unused73]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50359: AddedToken(\"[unused74]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50360: AddedToken(\"[unused75]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50361: AddedToken(\"[unused76]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50362: AddedToken(\"[unused77]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50363: AddedToken(\"[unused78]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50364: AddedToken(\"[unused79]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50365: AddedToken(\"[unused80]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50366: AddedToken(\"[unused81]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50367: AddedToken(\"[unused82]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b212ea5-f60d-41a3-927c-9183bea72e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler\n",
    "def create_dataset(texts, labels):\n",
    "    encodings = tokenizer(list(texts), truncation=True, padding=True, max_length=36, return_tensors='pt')\n",
    "    dataset = TensorDataset(encodings['input_ids'], encodings['attention_mask'], torch.tensor(labels)) # would work here\n",
    "    return dataset\n",
    "\n",
    "# label must be convert to list so it worked for torch.tensor (reference line 5)\n",
    "y_1 = y_train.to_list()\n",
    "y_2 = y_val.to_list()\n",
    "y_3 = y_test.to_list()\n",
    "\n",
    "train_dataset = create_dataset(X_train, y_1)\n",
    "val_dataset   = create_dataset(X_val, y_2)\n",
    "test_dataset  = create_dataset(X_test, y_3)\n",
    "\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=batch_size)\n",
    "val_loader   = DataLoader(val_dataset, sampler=SequentialSampler(val_dataset), batch_size=batch_size)\n",
    "test_loader  = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7fe1e0a-c625-48a3-8c73-cd58ce66d694",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/modernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device('cpu')\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "import torch.nn as nn\n",
    "\n",
    "model_id = \"answerdotai/modernBERT-base\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id, cache_dir = \"C:/Users/Abdullah Ghassan/.cache/huggingface/hub\",\n",
    "                                                          num_labels = 3)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr = 2e-5, eps=1e-8)\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "print(f\"Model device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4585b495-8244-46b6-b8f0-902d322a805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "'''\n",
    "helper function for time and model metrics\n",
    "'''\n",
    "def format_time(elapsed):\n",
    "    return str(elapsed)\n",
    "\n",
    "def calculate_metrics(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    acc = accuracy_score(labels_flat, pred_flat)\n",
    "    f1 = f1_score(labels_flat, pred_flat, average='macro') \n",
    "    return acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "baffa67b-3d2f-4296-9b58-ff84ed721c26",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dimulai... Model terbaik akan disimpan di: best_model_modernBERT.pt\n",
      "\n",
      "======== Epoch 1 / 8 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 688/688 [02:42<00:00,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Validation...\n",
      "\n",
      "  Hasil Epoch 1:\n",
      "  Training Loss    : 0.6086\n",
      "  Validation Loss  : 0.5332\n",
      "  Validation Acc   : 0.7731\n",
      "  Validation F1    : 0.6566 (Macro)\n",
      "  [INFO] F1 Score meningkat (0.0000 --> 0.6566). Menyimpan model...\n",
      "\n",
      "======== Epoch 2 / 8 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 688/688 [02:41<00:00,  4.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Validation...\n",
      "\n",
      "  Hasil Epoch 2:\n",
      "  Training Loss    : 0.3895\n",
      "  Validation Loss  : 0.5179\n",
      "  Validation Acc   : 0.8009\n",
      "  Validation F1    : 0.7053 (Macro)\n",
      "  [INFO] F1 Score meningkat (0.6566 --> 0.7053). Menyimpan model...\n",
      "\n",
      "======== Epoch 3 / 8 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 688/688 [02:42<00:00,  4.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Validation...\n",
      "\n",
      "  Hasil Epoch 3:\n",
      "  Training Loss    : 0.2306\n",
      "  Validation Loss  : 0.4961\n",
      "  Validation Acc   : 0.8449\n",
      "  Validation F1    : 0.7542 (Macro)\n",
      "  [INFO] F1 Score meningkat (0.7053 --> 0.7542). Menyimpan model...\n",
      "\n",
      "======== Epoch 4 / 8 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 688/688 [02:41<00:00,  4.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Validation...\n",
      "\n",
      "  Hasil Epoch 4:\n",
      "  Training Loss    : 0.1364\n",
      "  Validation Loss  : 0.8850\n",
      "  Validation Acc   : 0.8449\n",
      "  Validation F1    : 0.7607 (Macro)\n",
      "  [INFO] F1 Score meningkat (0.7542 --> 0.7607). Menyimpan model...\n",
      "\n",
      "======== Epoch 5 / 8 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 688/688 [02:42<00:00,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Validation...\n",
      "\n",
      "  Hasil Epoch 5:\n",
      "  Training Loss    : 0.0592\n",
      "  Validation Loss  : 1.2411\n",
      "  Validation Acc   : 0.8380\n",
      "  Validation F1    : 0.7484 (Macro)\n",
      "  [INFO] F1 Score tidak meningkat (Best: 0.7607).\n",
      "\n",
      "======== Epoch 6 / 8 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 688/688 [02:42<00:00,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Validation...\n",
      "\n",
      "  Hasil Epoch 6:\n",
      "  Training Loss    : 0.0203\n",
      "  Validation Loss  : 1.3176\n",
      "  Validation Acc   : 0.8310\n",
      "  Validation F1    : 0.7623 (Macro)\n",
      "  [INFO] F1 Score meningkat (0.7607 --> 0.7623). Menyimpan model...\n",
      "\n",
      "======== Epoch 7 / 8 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 688/688 [02:44<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Validation...\n",
      "\n",
      "  Hasil Epoch 7:\n",
      "  Training Loss    : 0.0162\n",
      "  Validation Loss  : 1.7001\n",
      "  Validation Acc   : 0.8032\n",
      "  Validation F1    : 0.6700 (Macro)\n",
      "  [INFO] F1 Score tidak meningkat (Best: 0.7623).\n",
      "\n",
      "======== Epoch 8 / 8 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 688/688 [02:41<00:00,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Validation...\n",
      "\n",
      "  Hasil Epoch 8:\n",
      "  Training Loss    : 0.0183\n",
      "  Validation Loss  : 1.6328\n",
      "  Validation Acc   : 0.8356\n",
      "  Validation F1    : 0.7455 (Macro)\n",
      "  [INFO] F1 Score tidak meningkat (Best: 0.7623).\n",
      "\n",
      "Training Selesai!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os # Untuk path file\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==========================================\n",
    "# PERSIAPAN PENYIMPANAN\n",
    "# ==========================================\n",
    "\n",
    "epochs = 8\n",
    "best_val_f1 = 0.0 # Rekor F1 tertinggi saat ini (inisialisasi 0)\n",
    "save_path = 'best_model_modernBERT.pt' # Nama file model\n",
    "\n",
    "print(f\"Training dimulai... Model terbaik akan disimpan di: {save_path}\")\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "    # training core\n",
    "    print(f'\\n======== Epoch {epoch_i + 1} / {epochs} ========')\n",
    "    print('Training...')\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_loader):\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        model.zero_grad()\n",
    "        \n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=None)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        loss = criterion(logits, b_labels)\n",
    "        if torch.isnan(loss):\n",
    "            print(\"Loss is NaN! Stopping training to debug.\")\n",
    "            # You can print other tensors here to inspect their values\n",
    "            # print(\"Logits:\", logits)\n",
    "            # print(\"Labels:\", b_labels)\n",
    "            break \n",
    "        total_train_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    \n",
    "    # --- FASE VALIDASI ---\n",
    "    print('\\nRunning Validation...')\n",
    "    model.eval()\n",
    "    \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_f1 = 0\n",
    "    total_eval_loss = 0\n",
    "\n",
    "    for batch in val_loader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=None)\n",
    "            logits = outputs.logits\n",
    "            loss = criterion(logits, b_labels)\n",
    "            \n",
    "        total_eval_loss += loss.item()\n",
    "        \n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        tmp_eval_accuracy, tmp_eval_f1 = calculate_metrics(logits, label_ids)\n",
    "        total_eval_accuracy += tmp_eval_accuracy\n",
    "        total_eval_f1 += tmp_eval_f1\n",
    "\n",
    "    avg_val_loss = total_eval_loss / len(val_loader)\n",
    "    avg_val_accuracy = total_eval_accuracy / len(val_loader)\n",
    "    avg_val_f1 = total_eval_f1 / len(val_loader)\n",
    "\n",
    "    print(f\"\\n  Hasil Epoch {epoch_i + 1}:\")\n",
    "    print(f\"  Training Loss    : {avg_train_loss:.4f}\")\n",
    "    print(f\"  Validation Loss  : {avg_val_loss:.4f}\")\n",
    "    print(f\"  Validation Acc   : {avg_val_accuracy:.4f}\")\n",
    "    print(f\"  Validation F1    : {avg_val_f1:.4f} (Macro)\")\n",
    "\n",
    "    # ==========================================\n",
    "    # LOGIKA SIMPAN MODEL TERBAIK (CHECKPOINT)\n",
    "    # ==========================================\n",
    "    # Kita simpan jika F1 Score saat ini lebih besar dari rekor sebelumnya\n",
    "    if avg_val_f1 > best_val_f1:\n",
    "        print(f\"  [INFO] F1 Score meningkat ({best_val_f1:.4f} --> {avg_val_f1:.4f}). Menyimpan model...\")\n",
    "        \n",
    "        # Update rekor\n",
    "        best_val_f1 = avg_val_f1\n",
    "        \n",
    "        # Simpan state_dict (bobotnya saja, lebih hemat memori)\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "    else:\n",
    "        print(f\"  [INFO] F1 Score tidak meningkat (Best: {best_val_f1:.4f}).\")\n",
    "\n",
    "print(\"\\nTraining Selesai!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee48a22-0aff-4c89-b3cb-3085b730705d",
   "metadata": {},
   "source": [
    "# Handle Class Imbalance + Evaluasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44ecb889-e372-4d19-898f-9743f16293e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/modernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "from torch.optim import AdamW\n",
    "import torch.nn as nn\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Hitung Class Weights (Penting untuk Imbalance!)\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "model_id = \"answerdotai/modernBERT-base\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id, cache_dir = \"C:/Users/Abdullah Ghassan/.cache/huggingface/hub\",\n",
    "                                                          num_labels = 3)\n",
    "model.to(device)\n",
    "state_dict = torch.load('best_model_modernBERT.pt', map_location=device)\n",
    "model.load_state_dict(state_dict)\n",
    "optimizer = AdamW(model.parameters(), lr = 2e-5, eps=1e-8)\n",
    "criterion = nn.CrossEntropyLoss(weight=weights_tensor) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51e10594-dd62-4936-a1f0-3d814da46e41",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dimulai... Model terbaik akan disimpan di: best_model_modernBERT_2.pt\n",
      "\n",
      "======== Epoch 1 / 8 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 688/688 [02:41<00:00,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Validation...\n",
      "\n",
      "  Hasil Epoch 1:\n",
      "  Training Loss    : 0.0257\n",
      "  Validation Loss  : 3.0072\n",
      "  Validation Acc   : 0.8403\n",
      "  Validation F1    : 0.7622 (Macro)\n",
      "  [INFO] F1 Score meningkat (0.0000 --> 0.7622). Menyimpan model...\n",
      "\n",
      "======== Epoch 2 / 8 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 688/688 [02:42<00:00,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Validation...\n",
      "\n",
      "  Hasil Epoch 2:\n",
      "  Training Loss    : 0.0202\n",
      "  Validation Loss  : 2.8112\n",
      "  Validation Acc   : 0.8310\n",
      "  Validation F1    : 0.7145 (Macro)\n",
      "  [INFO] F1 Score tidak meningkat (Best: 0.7622).\n",
      "\n",
      "======== Epoch 3 / 8 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 688/688 [02:41<00:00,  4.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Validation...\n",
      "\n",
      "  Hasil Epoch 3:\n",
      "  Training Loss    : 0.0327\n",
      "  Validation Loss  : 3.0040\n",
      "  Validation Acc   : 0.7986\n",
      "  Validation F1    : 0.7093 (Macro)\n",
      "  [INFO] F1 Score tidak meningkat (Best: 0.7622).\n",
      "\n",
      "======== Epoch 4 / 8 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 688/688 [02:41<00:00,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Validation...\n",
      "\n",
      "  Hasil Epoch 4:\n",
      "  Training Loss    : 0.0368\n",
      "  Validation Loss  : 3.1940\n",
      "  Validation Acc   : 0.8380\n",
      "  Validation F1    : 0.7555 (Macro)\n",
      "  [INFO] F1 Score tidak meningkat (Best: 0.7622).\n",
      "\n",
      "======== Epoch 5 / 8 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 688/688 [02:41<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Validation...\n",
      "\n",
      "  Hasil Epoch 5:\n",
      "  Training Loss    : 0.0153\n",
      "  Validation Loss  : 3.5489\n",
      "  Validation Acc   : 0.8380\n",
      "  Validation F1    : 0.7388 (Macro)\n",
      "  [INFO] F1 Score tidak meningkat (Best: 0.7622).\n",
      "\n",
      "======== Epoch 6 / 8 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 688/688 [02:41<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Validation...\n",
      "\n",
      "  Hasil Epoch 6:\n",
      "  Training Loss    : 0.0199\n",
      "  Validation Loss  : 3.6027\n",
      "  Validation Acc   : 0.8472\n",
      "  Validation F1    : 0.7456 (Macro)\n",
      "  [INFO] F1 Score tidak meningkat (Best: 0.7622).\n",
      "\n",
      "======== Epoch 7 / 8 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 688/688 [02:41<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Validation...\n",
      "\n",
      "  Hasil Epoch 7:\n",
      "  Training Loss    : 0.0347\n",
      "  Validation Loss  : 3.0344\n",
      "  Validation Acc   : 0.8449\n",
      "  Validation F1    : 0.7455 (Macro)\n",
      "  [INFO] F1 Score tidak meningkat (Best: 0.7622).\n",
      "\n",
      "======== Epoch 8 / 8 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 688/688 [02:41<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Validation...\n",
      "\n",
      "  Hasil Epoch 8:\n",
      "  Training Loss    : 0.0249\n",
      "  Validation Loss  : 3.2360\n",
      "  Validation Acc   : 0.8264\n",
      "  Validation F1    : 0.7175 (Macro)\n",
      "  [INFO] F1 Score tidak meningkat (Best: 0.7622).\n",
      "\n",
      "Training Selesai!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os # Untuk path file\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==========================================\n",
    "# PERSIAPAN PENYIMPANAN\n",
    "# ==========================================\n",
    "\n",
    "epochs = 8\n",
    "best_val_f1 = 0\n",
    "save_path = 'best_model_modernBERT_2.pt' # Nama file model\n",
    "\n",
    "print(f\"Training dimulai... Model terbaik akan disimpan di: {save_path}\")\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "    # training core\n",
    "    print(f'\\n======== Epoch {epoch_i + 1} / {epochs} ========')\n",
    "    print('Training...')\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_loader):\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        model.zero_grad()\n",
    "        \n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=None)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        loss = criterion(logits, b_labels)\n",
    "        if torch.isnan(loss):\n",
    "            print(\"Loss is NaN! Stopping training to debug.\")\n",
    "            # You can print other tensors here to inspect their values\n",
    "            # print(\"Logits:\", logits)\n",
    "            # print(\"Labels:\", b_labels)\n",
    "            break \n",
    "        total_train_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    \n",
    "    # --- FASE VALIDASI ---\n",
    "    print('\\nRunning Validation...')\n",
    "    model.eval()\n",
    "    \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_f1 = 0\n",
    "    total_eval_loss = 0\n",
    "\n",
    "    for batch in val_loader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=None)\n",
    "            logits = outputs.logits\n",
    "            loss = criterion(logits, b_labels)\n",
    "            \n",
    "        total_eval_loss += loss.item()\n",
    "        \n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        tmp_eval_accuracy, tmp_eval_f1 = calculate_metrics(logits, label_ids)\n",
    "        total_eval_accuracy += tmp_eval_accuracy\n",
    "        total_eval_f1 += tmp_eval_f1\n",
    "\n",
    "    avg_val_loss = total_eval_loss / len(val_loader)\n",
    "    avg_val_accuracy = total_eval_accuracy / len(val_loader)\n",
    "    avg_val_f1 = total_eval_f1 / len(val_loader)\n",
    "\n",
    "    print(f\"\\n  Hasil Epoch {epoch_i + 1}:\")\n",
    "    print(f\"  Training Loss    : {avg_train_loss:.4f}\")\n",
    "    print(f\"  Validation Loss  : {avg_val_loss:.4f}\")\n",
    "    print(f\"  Validation Acc   : {avg_val_accuracy:.4f}\")\n",
    "    print(f\"  Validation F1    : {avg_val_f1:.4f} (Macro)\")\n",
    "\n",
    "    # ==========================================\n",
    "    # LOGIKA SIMPAN MODEL TERBAIK (CHECKPOINT)\n",
    "    # ==========================================\n",
    "    # Kita simpan jika F1 Score saat ini lebih besar dari rekor sebelumnya\n",
    "    if avg_val_f1 > best_val_f1:\n",
    "        print(f\"  [INFO] F1 Score meningkat ({best_val_f1:.4f} --> {avg_val_f1:.4f}). Menyimpan model...\")\n",
    "        \n",
    "        # Update rekor\n",
    "        best_val_f1 = avg_val_f1\n",
    "        \n",
    "        # Simpan state_dict (bobotnya saja, lebih hemat memori)\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "    else:\n",
    "        print(f\"  [INFO] F1 Score tidak meningkat (Best: {best_val_f1:.4f}).\")\n",
    "\n",
    "print(\"\\nTraining Selesai!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34f2b0bf-5a2d-42f0-a579-c70cd01a1ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/modernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.74      0.66      0.70        87\n",
      "    Negative       0.82      0.75      0.78       263\n",
      "    Positive       0.88      0.93      0.90       490\n",
      "\n",
      "    accuracy                           0.85       840\n",
      "   macro avg       0.81      0.78      0.79       840\n",
      "weighted avg       0.84      0.85      0.84       840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "import torch\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model_id = \"answerdotai/modernBERT-base\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id, cache_dir = \"C:/Users/Abdullah Ghassan/.cache/huggingface/hub\",\n",
    "                                                          num_labels = 3)\n",
    "model.load_state_dict(torch.load('best_model_modernBERT_2.pt'))\n",
    "model.to(device) \n",
    "\n",
    "model.eval()\n",
    "predictions, true_labels = [], []\n",
    "\n",
    "for batch in test_loader:\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "    \n",
    "    logits = outputs.logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "    predictions.extend(np.argmax(logits, axis=1).flatten())\n",
    "    true_labels.extend(label_ids.flatten())\n",
    "\n",
    "print(classification_report(true_labels, predictions, target_names=['Neutral', 'Negative', 'Positive']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8dc03309-24ad-43fa-a81d-75eb6aaaf692",
   "metadata": {},
   "source": [
    "# **Model 2: RoBERTa**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e57a809-1bae-4e5e-9958-dd7f5fbee535",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dimulai... Model terbaik akan disimpan di: best_model_roberta.pt\n",
      "\n",
      "======== Epoch 1 / 8 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 688/688 [01:56<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Validation...\n",
      "\n",
      "  Hasil Epoch 1:\n",
      "  Training Loss    : 0.7988\n",
      "  Validation Loss  : 0.7742\n",
      "  Validation Acc   : 0.7292\n",
      "  Validation F1    : 0.6591 (Macro)\n",
      "  [INFO] F1 Score meningkat (0.0000 --> 0.6591). Menyimpan model...\n",
      "\n",
      "======== Epoch 2 / 8 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 688/688 [01:57<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Validation...\n",
      "\n",
      "  Hasil Epoch 2:\n",
      "  Training Loss    : 0.6031\n",
      "  Validation Loss  : 0.7467\n",
      "  Validation Acc   : 0.8171\n",
      "  Validation F1    : 0.7275 (Macro)\n",
      "  [INFO] F1 Score meningkat (0.6591 --> 0.7275). Menyimpan model...\n",
      "\n",
      "======== Epoch 3 / 8 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 688/688 [01:57<00:00,  5.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Validation...\n",
      "\n",
      "  Hasil Epoch 3:\n",
      "  Training Loss    : 0.5026\n",
      "  Validation Loss  : 0.7095\n",
      "  Validation Acc   : 0.8218\n",
      "  Validation F1    : 0.7226 (Macro)\n",
      "  [INFO] F1 Score tidak meningkat (Best: 0.7275).\n",
      "\n",
      "======== Epoch 4 / 8 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 688/688 [01:57<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Validation...\n",
      "\n",
      "  Hasil Epoch 4:\n",
      "  Training Loss    : 0.4355\n",
      "  Validation Loss  : 0.6887\n",
      "  Validation Acc   : 0.8194\n",
      "  Validation F1    : 0.7225 (Macro)\n",
      "  [INFO] F1 Score tidak meningkat (Best: 0.7275).\n",
      "\n",
      "======== Epoch 5 / 8 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 688/688 [01:57<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Validation...\n",
      "\n",
      "  Hasil Epoch 5:\n",
      "  Training Loss    : 0.3849\n",
      "  Validation Loss  : 0.8237\n",
      "  Validation Acc   : 0.8218\n",
      "  Validation F1    : 0.6972 (Macro)\n",
      "  [INFO] F1 Score tidak meningkat (Best: 0.7275).\n",
      "\n",
      "======== Epoch 6 / 8 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 688/688 [01:57<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Validation...\n",
      "\n",
      "  Hasil Epoch 6:\n",
      "  Training Loss    : 0.3469\n",
      "  Validation Loss  : 0.9616\n",
      "  Validation Acc   : 0.8333\n",
      "  Validation F1    : 0.7090 (Macro)\n",
      "  [INFO] F1 Score tidak meningkat (Best: 0.7275).\n",
      "\n",
      "======== Epoch 7 / 8 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 688/688 [01:57<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Validation...\n",
      "\n",
      "  Hasil Epoch 7:\n",
      "  Training Loss    : 0.3165\n",
      "  Validation Loss  : 0.8922\n",
      "  Validation Acc   : 0.8380\n",
      "  Validation F1    : 0.7373 (Macro)\n",
      "  [INFO] F1 Score meningkat (0.7275 --> 0.7373). Menyimpan model...\n",
      "\n",
      "======== Epoch 8 / 8 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 688/688 [01:57<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Validation...\n",
      "\n",
      "  Hasil Epoch 8:\n",
      "  Training Loss    : 0.2803\n",
      "  Validation Loss  : 1.0531\n",
      "  Validation Acc   : 0.8310\n",
      "  Validation F1    : 0.7240 (Macro)\n",
      "  [INFO] F1 Score tidak meningkat (Best: 0.7373).\n",
      "\n",
      "Training Selesai!\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.85      0.69      0.76        87\n",
      "    Negative       0.75      0.84      0.79       263\n",
      "    Positive       0.91      0.88      0.90       490\n",
      "\n",
      "    accuracy                           0.85       840\n",
      "   macro avg       0.83      0.80      0.82       840\n",
      "weighted avg       0.85      0.85      0.85       840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "from torch.optim import AdamW\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hitung Class Weights (Penting untuk Imbalance!)\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "model_id = \"FacebookAI/roberta-base\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id, cache_dir = \"C:/Users/Abdullah Ghassan/.cache/huggingface/hub\",\n",
    "                                                          num_labels = 3)\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr = 2e-5, eps=1e-8)\n",
    "criterion = nn.CrossEntropyLoss(weight=weights_tensor) \n",
    "\n",
    "import torch.nn.functional as F\n",
    "import os # Untuk path file\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "'''\n",
    "helper function for time and model metrics\n",
    "'''\n",
    "def format_time(elapsed):\n",
    "    return str(elapsed)\n",
    "\n",
    "def calculate_metrics(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    acc = accuracy_score(labels_flat, pred_flat)\n",
    "    f1 = f1_score(labels_flat, pred_flat, average='macro') \n",
    "    return acc, f1\n",
    "\n",
    "# ==========================================\n",
    "# PERSIAPAN PENYIMPANAN\n",
    "# ==========================================\n",
    "\n",
    "epochs = 8\n",
    "best_val_f1 = 0\n",
    "save_path = 'best_model_roberta.pt' # Nama file model\n",
    "\n",
    "print(f\"Training dimulai... Model terbaik akan disimpan di: {save_path}\")\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "    # training core\n",
    "    print(f'\\n======== Epoch {epoch_i + 1} / {epochs} ========')\n",
    "    print('Training...')\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_loader):\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        model.zero_grad()\n",
    "        \n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=None)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        loss = criterion(logits, b_labels)\n",
    "        if torch.isnan(loss):\n",
    "            print(\"Loss is NaN! Stopping training to debug.\")\n",
    "            # You can print other tensors here to inspect their values\n",
    "            # print(\"Logits:\", logits)\n",
    "            # print(\"Labels:\", b_labels)\n",
    "            break \n",
    "        total_train_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    \n",
    "    # --- FASE VALIDASI ---\n",
    "    print('\\nRunning Validation...')\n",
    "    model.eval()\n",
    "    \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_f1 = 0\n",
    "    total_eval_loss = 0\n",
    "\n",
    "    for batch in val_loader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=None)\n",
    "            logits = outputs.logits\n",
    "            loss = criterion(logits, b_labels)\n",
    "            \n",
    "        total_eval_loss += loss.item()\n",
    "        \n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        tmp_eval_accuracy, tmp_eval_f1 = calculate_metrics(logits, label_ids)\n",
    "        total_eval_accuracy += tmp_eval_accuracy\n",
    "        total_eval_f1 += tmp_eval_f1\n",
    "\n",
    "    avg_val_loss = total_eval_loss / len(val_loader)\n",
    "    avg_val_accuracy = total_eval_accuracy / len(val_loader)\n",
    "    avg_val_f1 = total_eval_f1 / len(val_loader)\n",
    "\n",
    "    print(f\"\\n  Hasil Epoch {epoch_i + 1}:\")\n",
    "    print(f\"  Training Loss    : {avg_train_loss:.4f}\")\n",
    "    print(f\"  Validation Loss  : {avg_val_loss:.4f}\")\n",
    "    print(f\"  Validation Acc   : {avg_val_accuracy:.4f}\")\n",
    "    print(f\"  Validation F1    : {avg_val_f1:.4f} (Macro)\")\n",
    "\n",
    "    # ==========================================\n",
    "    # LOGIKA SIMPAN MODEL TERBAIK (CHECKPOINT)\n",
    "    # ==========================================\n",
    "    # Kita simpan jika F1 Score saat ini lebih besar dari rekor sebelumnya\n",
    "    if avg_val_f1 > best_val_f1:\n",
    "        print(f\"  [INFO] F1 Score meningkat ({best_val_f1:.4f} --> {avg_val_f1:.4f}). Menyimpan model...\")\n",
    "        \n",
    "        # Update rekor\n",
    "        best_val_f1 = avg_val_f1\n",
    "        \n",
    "        # Simpan state_dict (bobotnya saja, lebih hemat memori)\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "    else:\n",
    "        print(f\"  [INFO] F1 Score tidak meningkat (Best: {best_val_f1:.4f}).\")\n",
    "\n",
    "print(\"\\nTraining Selesai!\")\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model.eval()\n",
    "predictions, true_labels = [], []\n",
    "\n",
    "for batch in test_loader:\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "    \n",
    "    logits = outputs.logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "    predictions.extend(np.argmax(logits, axis=1).flatten())\n",
    "    true_labels.extend(label_ids.flatten())\n",
    "\n",
    "print(classification_report(true_labels, predictions, target_names=['Neutral', 'Negative', 'Positive']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b1281a-b8f3-4ca4-919e-02fea4843756",
   "metadata": {},
   "source": [
    "# Komparasi ModernBERT vs RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64fd6a56-e19f-4b7f-b122-c8c0291603f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data dari user\n",
    "metrics = ['Accuracy', 'Macro Precision', 'Macro Recall', 'Macro F1 Score']\n",
    "\n",
    "modernbert_scores = [0.85, 0.81, 0.78, 0.79]\n",
    "\n",
    "# Nilai untuk IndoBERT\n",
    "# Acc: 0.93, Macro Prec: 0.91, Macro Rec: 0.89, Macro F1: 0.90\n",
    "roberta_scores = [0.85, 0.83, 0.80, 0.82]\n",
    "\n",
    "x = np.arange(len(metrics))  # Lokasi label\n",
    "width = 0.35  # Lebar bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "rects1 = ax.bar(x - width/2, modernbert_scores, width, label='ModernBERT', color='#4e79a7')\n",
    "rects2 = ax.bar(x + width/2, roberta_scores, width, label='RoBERTa', color='#f28e2b')\n",
    "\n",
    "# Menambahkan teks label, judul, dan penanda sumbu\n",
    "ax.set_ylabel('Score (0-1)')\n",
    "ax.set_title('Perbandingan Performa Model: ModernBERT vs RoBERTa')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.set_ylim(0, 1.1) # Memberi ruang untuk label angka di atas bar\n",
    "ax.legend(loc='lower left')\n",
    "\n",
    "# Fungsi untuk menampilkan nilai di atas bar\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f'{height:.2f}',\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006ccc4d-abb4-4380-8896-52562a5e2422",
   "metadata": {},
   "source": [
    "# Minta RoBERTa prediski dengan data terurut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6de00450-6e61-4755-a184-fdb400dfacf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp = test['clean_text']\n",
    "y_temp = test['label']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=2/3, shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9aec438-b94c-468b-a910-40729613ab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler\n",
    "# def create_dataset(texts, labels):\n",
    "#     encodings = tokenizer(list(texts), truncation=True, padding=True, max_length=36, return_tensors='pt')\n",
    "#     dataset = TensorDataset(encodings['input_ids'], encodings['attention_mask'], torch.tensor(labels)) # would work here\n",
    "#     return dataset\n",
    "\n",
    "# label must be convert to list so it worked for torch.tensor (reference line 5)\n",
    "y_3 = y_test.to_list()\n",
    "test_dataset  = create_dataset(X_test, y_3)\n",
    "\n",
    "batch_size = 16\n",
    "test_loader  = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96a715d5-061e-4e06-b0e4-bfbc72e75959",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.72      0.70      0.71        87\n",
      "    Negative       0.82      0.73      0.77       263\n",
      "    Positive       0.88      0.93      0.90       490\n",
      "\n",
      "    accuracy                           0.85       840\n",
      "   macro avg       0.80      0.79      0.80       840\n",
      "weighted avg       0.84      0.85      0.84       840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "import torch\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model_id = \"FacebookAI/roberta-base\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id, cache_dir = \"C:/Users/Abdullah Ghassan/.cache/huggingface/hub\",\n",
    "                                                          num_labels = 3)\n",
    "model.load_state_dict(torch.load('best_model_roberta.pt'))\n",
    "model.to(device) \n",
    "\n",
    "model.eval()\n",
    "predictions, true_labels = [], []\n",
    "\n",
    "for batch in test_loader:\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "    \n",
    "    logits = outputs.logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "    predictions.extend(np.argmax(logits, axis=1).flatten())\n",
    "    true_labels.extend(label_ids.flatten())\n",
    "\n",
    "print(classification_report(true_labels, predictions, target_names=['Neutral', 'Negative', 'Positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b961ea05-1cee-4374-a216-1fbe3b3401d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['softeng.joblib']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump((train, test, true_labels, predictions), 'softeng.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e197c514-0e55-4f50-88ca-a34352b3e585",
   "metadata": {},
   "source": [
    "# Algoritma merge sample dengan hasil prediksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a4b89b8f-443b-4029-9410-bbd1a77dfb91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>label</th>\n",
       "      <th>prediksi_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>420</td>\n",
       "      <td>ustad bajingan seperti ustadtengkuzul sudah ka...</td>\n",
       "      <td>negative</td>\n",
       "      <td>ustad bajingan seperti ustadtengkuzul sudah ka...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>421</td>\n",
       "      <td>lihatlah wahai netizen . apakah kalian masih p...</td>\n",
       "      <td>negative</td>\n",
       "      <td>lihatlah wahai netizen . apakah kalian masih p...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>422</td>\n",
       "      <td>siapkan payung jika ke sini siang hari . suasa...</td>\n",
       "      <td>positive</td>\n",
       "      <td>siapkan payung jika ke sini siang hari . suasa...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>423</td>\n",
       "      <td>tribun : gubernur anies : kami ingin pasar sen...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>tribun gubernur anies kami ingin pasar senen j...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>424</td>\n",
       "      <td>lailah banyak banget akun sampah model begini ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>lailah banyak banget akun sampah model begini ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>1255</td>\n",
       "      <td>film tncfu , tidak cocok untuk penonton yang t...</td>\n",
       "      <td>negative</td>\n",
       "      <td>film tncfu , tidak cocok untuk penonton yang t...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>1256</td>\n",
       "      <td>indihome ini mahal loh bayar nya . hanya , pen...</td>\n",
       "      <td>negative</td>\n",
       "      <td>indihome ini mahal loh bayar nya . hanya , pen...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>1257</td>\n",
       "      <td>be de gea , cowok cupu yang takut dengan pacar...</td>\n",
       "      <td>negative</td>\n",
       "      <td>be de gea , cowok cupu yang takut dengan pacar...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>1258</td>\n",
       "      <td>valen yang sangat tidak berkualitas . konentat...</td>\n",
       "      <td>negative</td>\n",
       "      <td>valen yang sangat tidak berkualitas . konentat...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>1259</td>\n",
       "      <td>restoran ini menjadi tempat pilihan saya berbu...</td>\n",
       "      <td>positive</td>\n",
       "      <td>restoran ini menjadi tempat pilihan saya berbu...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>840 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                               text sentiment  \\\n",
       "0      420  ustad bajingan seperti ustadtengkuzul sudah ka...  negative   \n",
       "1      421  lihatlah wahai netizen . apakah kalian masih p...  negative   \n",
       "2      422  siapkan payung jika ke sini siang hari . suasa...  positive   \n",
       "3      423  tribun : gubernur anies : kami ingin pasar sen...   neutral   \n",
       "4      424  lailah banyak banget akun sampah model begini ...  negative   \n",
       "..     ...                                                ...       ...   \n",
       "835   1255  film tncfu , tidak cocok untuk penonton yang t...  negative   \n",
       "836   1256  indihome ini mahal loh bayar nya . hanya , pen...  negative   \n",
       "837   1257  be de gea , cowok cupu yang takut dengan pacar...  negative   \n",
       "838   1258  valen yang sangat tidak berkualitas . konentat...  negative   \n",
       "839   1259  restoran ini menjadi tempat pilihan saya berbu...  positive   \n",
       "\n",
       "                                            clean_text  label  prediksi_model  \n",
       "0    ustad bajingan seperti ustadtengkuzul sudah ka...      1               1  \n",
       "1    lihatlah wahai netizen . apakah kalian masih p...      1               1  \n",
       "2    siapkan payung jika ke sini siang hari . suasa...      2               2  \n",
       "3    tribun gubernur anies kami ingin pasar senen j...      0               0  \n",
       "4    lailah banyak banget akun sampah model begini ...      1               2  \n",
       "..                                                 ...    ...             ...  \n",
       "835  film tncfu , tidak cocok untuk penonton yang t...      1               1  \n",
       "836  indihome ini mahal loh bayar nya . hanya , pen...      1               1  \n",
       "837  be de gea , cowok cupu yang takut dengan pacar...      1               1  \n",
       "838  valen yang sangat tidak berkualitas . konentat...      1               1  \n",
       "839  restoran ini menjadi tempat pilihan saya berbu...      2               2  \n",
       "\n",
       "[840 rows x 6 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "goals: merge sample input buat model prediksi (untuk kasus ini contohnya sample input = test dataframe) dengan hasil prediksi\n",
    "\n",
    "slicing logic -> test.iloc[1259-839:] (slicing 839 baris terakhir dari dataframe) [1]\n",
    "code row_start untuk df_temp = iloc dibawah berdasarkan logic dari referensi [1] supaya bisa slicing secara dinamis, berapapun panjang dari sample input\n",
    "\n",
    "flow: slicing ->  reset index sample dan hasil prediksi -> merge\n",
    "\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "row_start = test.shape[0] - len(predictions) \n",
    "df_temp = test.iloc[row_start:]\n",
    "df_temp = df_temp.reset_index()\n",
    "pred_temp = pd.Series(predictions, name = 'prediksi_model')\n",
    "result2 = pd.merge(df_temp, pred_temp, left_index = True, right_index = True, how = 'left')\n",
    "result2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2924f436-2162-410d-a8bf-32cff85c68d2",
   "metadata": {},
   "source": [
    "# Algoritma ambil data dengan sentiment yang negative saja\n",
    "\n",
    "## data dengan sentiment yang negative ini akan dijadikan input ke topic modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "282c7455-4f83-4600-b4f9-35fb28da572c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>label</th>\n",
       "      <th>prediksi_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>420</td>\n",
       "      <td>ustad bajingan seperti ustadtengkuzul sudah ka...</td>\n",
       "      <td>negative</td>\n",
       "      <td>ustad bajingan seperti ustadtengkuzul sudah ka...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>421</td>\n",
       "      <td>lihatlah wahai netizen . apakah kalian masih p...</td>\n",
       "      <td>negative</td>\n",
       "      <td>lihatlah wahai netizen . apakah kalian masih p...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>430</td>\n",
       "      <td>kayak nya mendingan gocar deh</td>\n",
       "      <td>positive</td>\n",
       "      <td>kayak nya mendingan gocar deh</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>431</td>\n",
       "      <td>tidak ganteng</td>\n",
       "      <td>negative</td>\n",
       "      <td>tidak ganteng</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>433</td>\n",
       "      <td>bandung macet banget ada apa si</td>\n",
       "      <td>negative</td>\n",
       "      <td>bandung macet banget ada apa si</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>1253</td>\n",
       "      <td>gila saja sih nih handphone samsung mahal bang...</td>\n",
       "      <td>negative</td>\n",
       "      <td>gila saja sih nih handphone samsung mahal bang...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>1255</td>\n",
       "      <td>film tncfu , tidak cocok untuk penonton yang t...</td>\n",
       "      <td>negative</td>\n",
       "      <td>film tncfu , tidak cocok untuk penonton yang t...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>1256</td>\n",
       "      <td>indihome ini mahal loh bayar nya . hanya , pen...</td>\n",
       "      <td>negative</td>\n",
       "      <td>indihome ini mahal loh bayar nya . hanya , pen...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>1257</td>\n",
       "      <td>be de gea , cowok cupu yang takut dengan pacar...</td>\n",
       "      <td>negative</td>\n",
       "      <td>be de gea , cowok cupu yang takut dengan pacar...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>1258</td>\n",
       "      <td>valen yang sangat tidak berkualitas . konentat...</td>\n",
       "      <td>negative</td>\n",
       "      <td>valen yang sangat tidak berkualitas . konentat...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>229 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                               text sentiment  \\\n",
       "0      420  ustad bajingan seperti ustadtengkuzul sudah ka...  negative   \n",
       "1      421  lihatlah wahai netizen . apakah kalian masih p...  negative   \n",
       "10     430                      kayak nya mendingan gocar deh  positive   \n",
       "11     431                                      tidak ganteng  negative   \n",
       "13     433                    bandung macet banget ada apa si  negative   \n",
       "..     ...                                                ...       ...   \n",
       "833   1253  gila saja sih nih handphone samsung mahal bang...  negative   \n",
       "835   1255  film tncfu , tidak cocok untuk penonton yang t...  negative   \n",
       "836   1256  indihome ini mahal loh bayar nya . hanya , pen...  negative   \n",
       "837   1257  be de gea , cowok cupu yang takut dengan pacar...  negative   \n",
       "838   1258  valen yang sangat tidak berkualitas . konentat...  negative   \n",
       "\n",
       "                                            clean_text  label  prediksi_model  \n",
       "0    ustad bajingan seperti ustadtengkuzul sudah ka...      1               1  \n",
       "1    lihatlah wahai netizen . apakah kalian masih p...      1               1  \n",
       "10                       kayak nya mendingan gocar deh      2               1  \n",
       "11                                       tidak ganteng      1               1  \n",
       "13                     bandung macet banget ada apa si      1               1  \n",
       "..                                                 ...    ...             ...  \n",
       "833  gila saja sih nih handphone samsung mahal bang...      1               1  \n",
       "835  film tncfu , tidak cocok untuk penonton yang t...      1               1  \n",
       "836  indihome ini mahal loh bayar nya . hanya , pen...      1               1  \n",
       "837  be de gea , cowok cupu yang takut dengan pacar...      1               1  \n",
       "838  valen yang sangat tidak berkualitas . konentat...      1               1  \n",
       "\n",
       "[229 rows x 6 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_modelling_input = result2.loc[result2['prediksi_model'] == 1]\n",
    "topic_modelling_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d87b84fd-9a9c-48d5-b4e0-83cede51d8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['softeng.joblib']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump((train, test, true_labels, predictions, topic_modelling_input, sbert_input, sbert_output, umap_output, hdb_machine, topics, probs, topic_modelling_output, topic_info), 'softeng.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa38843b-f5fd-4072-a005-332ec9b5e929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "train, test, true_labels, predictions, topic_modelling_input, sbert_input, sbert_output, umap_output, hdb_machine, topics, probs, topic_modelling_output, topic_info = joblib.load('softeng.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b09a5cf8-a14e-4666-bdd6-b223ee45ce6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['backend.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump((topics, probs), 'backend.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9a16e17-eb95-470b-b046-dd743747c64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import signal\n",
    "import subprocess\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e9808ed-4a84-4bd8-8833-99dcdd6a6b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, signal, subprocess, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9aea2795-dba2-45ee-8248-64bf9a1b8f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List\n",
    "def merge_sample_topic(test:pd.DataFrame, predictions: List[int]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    input: dataframe and list of predicted topic\n",
    "    process: merge dataframe and predicted topic\n",
    "    output: return a dtaframe which consist a predicted topic column\n",
    "    \"\"\"\n",
    "    row_start = test.shape[0] - len(predictions) \n",
    "    df_temp = test.iloc[row_start:]\n",
    "    df_temp.reset_index(inplace = True)\n",
    "    df_temp.drop('level_0', axis = 1, inplace =True)\n",
    "    pred_temp = pd.Series(predictions, name = 'topics')\n",
    "    result2 = pd.merge(df_temp, pred_temp, left_index = True, right_index = True, how = 'left')\n",
    "    return result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e348370b-af80-4188-abad-774853b66263",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_modelling_output = merge_sample_topic(topic_modelling_input, topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b316de29-4704-44e9-aabf-77b67d35652f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>label</th>\n",
       "      <th>prediksi_model</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>420</td>\n",
       "      <td>ustad bajingan seperti ustadtengkuzul sudah ka...</td>\n",
       "      <td>negative</td>\n",
       "      <td>ustad bajingan seperti ustadtengkuzul sudah ka...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>421</td>\n",
       "      <td>lihatlah wahai netizen . apakah kalian masih p...</td>\n",
       "      <td>negative</td>\n",
       "      <td>lihatlah wahai netizen . apakah kalian masih p...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>430</td>\n",
       "      <td>kayak nya mendingan gocar deh</td>\n",
       "      <td>positive</td>\n",
       "      <td>kayak nya mendingan gocar deh</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>431</td>\n",
       "      <td>tidak ganteng</td>\n",
       "      <td>negative</td>\n",
       "      <td>tidak ganteng</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>433</td>\n",
       "      <td>bandung macet banget ada apa si</td>\n",
       "      <td>negative</td>\n",
       "      <td>bandung macet banget ada apa si</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>1253</td>\n",
       "      <td>gila saja sih nih handphone samsung mahal bang...</td>\n",
       "      <td>negative</td>\n",
       "      <td>gila saja sih nih handphone samsung mahal bang...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>1255</td>\n",
       "      <td>film tncfu , tidak cocok untuk penonton yang t...</td>\n",
       "      <td>negative</td>\n",
       "      <td>film tncfu , tidak cocok untuk penonton yang t...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>1256</td>\n",
       "      <td>indihome ini mahal loh bayar nya . hanya , pen...</td>\n",
       "      <td>negative</td>\n",
       "      <td>indihome ini mahal loh bayar nya . hanya , pen...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>1257</td>\n",
       "      <td>be de gea , cowok cupu yang takut dengan pacar...</td>\n",
       "      <td>negative</td>\n",
       "      <td>be de gea , cowok cupu yang takut dengan pacar...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>1258</td>\n",
       "      <td>valen yang sangat tidak berkualitas . konentat...</td>\n",
       "      <td>negative</td>\n",
       "      <td>valen yang sangat tidak berkualitas . konentat...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>229 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                               text sentiment  \\\n",
       "0      420  ustad bajingan seperti ustadtengkuzul sudah ka...  negative   \n",
       "1      421  lihatlah wahai netizen . apakah kalian masih p...  negative   \n",
       "2      430                      kayak nya mendingan gocar deh  positive   \n",
       "3      431                                      tidak ganteng  negative   \n",
       "4      433                    bandung macet banget ada apa si  negative   \n",
       "..     ...                                                ...       ...   \n",
       "224   1253  gila saja sih nih handphone samsung mahal bang...  negative   \n",
       "225   1255  film tncfu , tidak cocok untuk penonton yang t...  negative   \n",
       "226   1256  indihome ini mahal loh bayar nya . hanya , pen...  negative   \n",
       "227   1257  be de gea , cowok cupu yang takut dengan pacar...  negative   \n",
       "228   1258  valen yang sangat tidak berkualitas . konentat...  negative   \n",
       "\n",
       "                                            clean_text  label  prediksi_model  \\\n",
       "0    ustad bajingan seperti ustadtengkuzul sudah ka...      1               1   \n",
       "1    lihatlah wahai netizen . apakah kalian masih p...      1               1   \n",
       "2                        kayak nya mendingan gocar deh      2               1   \n",
       "3                                        tidak ganteng      1               1   \n",
       "4                      bandung macet banget ada apa si      1               1   \n",
       "..                                                 ...    ...             ...   \n",
       "224  gila saja sih nih handphone samsung mahal bang...      1               1   \n",
       "225  film tncfu , tidak cocok untuk penonton yang t...      1               1   \n",
       "226  indihome ini mahal loh bayar nya . hanya , pen...      1               1   \n",
       "227  be de gea , cowok cupu yang takut dengan pacar...      1               1   \n",
       "228  valen yang sangat tidak berkualitas . konentat...      1               1   \n",
       "\n",
       "     topics  \n",
       "0         0  \n",
       "1         0  \n",
       "2        -1  \n",
       "3        -1  \n",
       "4         1  \n",
       "..      ...  \n",
       "224       1  \n",
       "225       1  \n",
       "226       1  \n",
       "227      -1  \n",
       "228       0  \n",
       "\n",
       "[229 rows x 7 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_modelling_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7c24932-71b0-4f2f-82e7-6c5a66d5379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_topwords(topic_model):\n",
    "    topic_info = topic_model.get_topic_info()\n",
    "    topic_descriptions = {}\n",
    "    for topic_id in topic_info['Topic']:\n",
    "        if topic_id == -1: \n",
    "            continue\n",
    "        words = [word for word, _ in topic_model.get_topic(topic_id)]\n",
    "        topic_descriptions[topic_id] = \", \".join(words[:10])\n",
    "    return topic_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e22e8c8-ad62-4b75-b6f8-893f617bad66",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_descriptions = extract_topwords(topic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f585a73-b893-4c0a-97d8-867ec735eb62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'itu, nya, yang, ini, tidak, di, jokowi, saja, sudah, dan',\n",
       " 1: 'tidak, saya, indosat, marah, nya, di, yang, aku, ya, sudah',\n",
       " 2: 'nya, di, makan, dan, yang, tidak, dengan, makanan, kami, tapi',\n",
       " 3: 'melelahkan, kagum, titik, minggu, killer, kelas, perjalanan, menyenangkan, efisien, tidur'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8ed66ebf-72b1-47ea-a11f-abfef57714da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_topic_label(top_words: str) -> str:\n",
    "    \"\"\"\n",
    "    input: one unit sentence text (string)\n",
    "    process: ask LLM to inference topic into one to two words\n",
    "    output: return one to two words \n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"Based on the following key terms, give a short, clear, and general topic name (2-4 words max):\n",
    "    \n",
    "    Key terms: {top_words}\n",
    "    \n",
    "    Topic name:\"\"\"\n",
    "    \n",
    "    response = llm(prompt, max_new_tokens=10, do_sample=False)\n",
    "    \n",
    "    # Extract generated text (adjust based on tokenizer/chat template)\n",
    "    generated = response[0]['generated_text'].split(\"Topic name:\")[-1].strip()\n",
    "    return generated.split(\"\\n\")[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1b5d91af-fc37-4a86-8e66-81a74986c912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f49a74c18bd4055bb4b9d4fc954ca14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m refined_labels \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m topic_id, words \u001b[38;5;129;01min\u001b[39;00m topic_descriptions\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m---> 13\u001b[0m     refined_labels[topic_id] \u001b[38;5;241m=\u001b[39m \u001b[43mrefine_topic_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[37], line 13\u001b[0m, in \u001b[0;36mrefine_topic_label\u001b[1;34m(top_words)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03minput: one unit sentence text (string)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03mprocess: ask LLM to inference topic into one to two words\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03moutput: return one to two words \u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      7\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mBased on the following key terms, give a short, clear, and general topic name (2-4 words max):\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124m\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124mKey terms: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtop_words\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124m\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124mTopic name:\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 13\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Extract generated text (adjust based on tokenizer/chat template)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m generated \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTopic name:\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\tf\\lib\\site-packages\\transformers\\pipelines\\text_generation.py:332\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[1;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[0;32m    330\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    331\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mlist\u001b[39m(chats), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(text_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\tf\\lib\\site-packages\\transformers\\pipelines\\base.py:1467\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1459\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[0;32m   1460\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[0;32m   1461\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1464\u001b[0m         )\n\u001b[0;32m   1465\u001b[0m     )\n\u001b[0;32m   1466\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1467\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\tf\\lib\\site-packages\\transformers\\pipelines\\base.py:1474\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[1;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[0;32m   1472\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[0;32m   1473\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[1;32m-> 1474\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[0;32m   1475\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[0;32m   1476\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\tf\\lib\\site-packages\\transformers\\pipelines\\base.py:1374\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m   1372\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[0;32m   1373\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m-> 1374\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[0;32m   1375\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\tf\\lib\\site-packages\\transformers\\pipelines\\text_generation.py:432\u001b[0m, in \u001b[0;36mTextGenerationPipeline._forward\u001b[1;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[0;32m    430\u001b[0m     generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_config\n\u001b[1;32m--> 432\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgenerate(input_ids\u001b[38;5;241m=\u001b[39minput_ids, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgenerate_kwargs)\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ModelOutput):\n\u001b[0;32m    435\u001b[0m     generated_sequence \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39msequences\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\tf\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\tf\\lib\\site-packages\\transformers\\generation\\utils.py:2564\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[0;32m   2561\u001b[0m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m generation_config\u001b[38;5;241m.\u001b[39muse_cache\n\u001b[0;32m   2563\u001b[0m \u001b[38;5;66;03m# 9. Call generation mode\u001b[39;00m\n\u001b[1;32m-> 2564\u001b[0m result \u001b[38;5;241m=\u001b[39m decoding_method(\n\u001b[0;32m   2565\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2566\u001b[0m     input_ids,\n\u001b[0;32m   2567\u001b[0m     logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[0;32m   2568\u001b[0m     stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[0;32m   2569\u001b[0m     generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   2570\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgeneration_mode_kwargs,\n\u001b[0;32m   2571\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2572\u001b[0m )\n\u001b[0;32m   2574\u001b[0m \u001b[38;5;66;03m# Convert to legacy cache format if requested\u001b[39;00m\n\u001b[0;32m   2575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2576\u001b[0m     generation_config\u001b[38;5;241m.\u001b[39mreturn_legacy_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   2577\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(result, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2578\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(result\u001b[38;5;241m.\u001b[39mpast_key_values, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_legacy_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2579\u001b[0m ):\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\tf\\lib\\site-packages\\transformers\\generation\\utils.py:2787\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[0;32m   2785\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   2786\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2787\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   2789\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[0;32m   2790\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[0;32m   2791\u001b[0m     outputs,\n\u001b[0;32m   2792\u001b[0m     model_kwargs,\n\u001b[0;32m   2793\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   2794\u001b[0m )\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\tf\\lib\\site-packages\\transformers\\utils\\generic.py:918\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    917\u001b[0m     return_dict \u001b[38;5;241m=\u001b[39m return_dict_passed\n\u001b[1;32m--> 918\u001b[0m output \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    919\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    920\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\tf\\lib\\site-packages\\transformers\\models\\phi3\\modeling_phi3.py:465\u001b[0m, in \u001b[0;36mPhi3ForCausalLM.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;129m@can_return_tuple\u001b[39m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;129m@auto_docstring\u001b[39m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Unpack[TransformersKwargs],\n\u001b[0;32m    447\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CausalLMOutputWithPast:\n\u001b[0;32m    448\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m    Example:\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;124;03m    \"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;124;03m    ```\"\"\"\u001b[39;00m\n\u001b[1;32m--> 465\u001b[0m     outputs: BaseModelOutputWithPast \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[0;32m    466\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m    467\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m    468\u001b[0m         position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m    469\u001b[0m         past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m    470\u001b[0m         inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[0;32m    471\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m    472\u001b[0m         cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[0;32m    473\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    474\u001b[0m     )\n\u001b[0;32m    476\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\tf\\lib\\site-packages\\transformers\\utils\\generic.py:1072\u001b[0m, in \u001b[0;36mcheck_model_inputs.<locals>.wrapped_fn.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1069\u001b[0m                 monkey_patched_layers\u001b[38;5;241m.\u001b[39mappend((module, original_forward))\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1072\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1073\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m original_exception:\n\u001b[0;32m   1074\u001b[0m     \u001b[38;5;66;03m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[39;00m\n\u001b[0;32m   1075\u001b[0m     \u001b[38;5;66;03m# Get a TypeError even after removing the recordable kwargs -> re-raise the original exception\u001b[39;00m\n\u001b[0;32m   1076\u001b[0m     \u001b[38;5;66;03m# Otherwise -> we're probably missing `**kwargs` in the decorated function\u001b[39;00m\n\u001b[0;32m   1077\u001b[0m     kwargs_without_recordable \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m recordable_keys}\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\tf\\lib\\site-packages\\transformers\\models\\phi3\\modeling_phi3.py:401\u001b[0m, in \u001b[0;36mPhi3Model.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[0;32m    398\u001b[0m position_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrotary_emb(hidden_states, position_ids)\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m decoder_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers]:\n\u001b[1;32m--> 401\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m decoder_layer(\n\u001b[0;32m    402\u001b[0m         hidden_states,\n\u001b[0;32m    403\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mcausal_mask,\n\u001b[0;32m    404\u001b[0m         position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m    405\u001b[0m         past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m    406\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m    407\u001b[0m         cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[0;32m    408\u001b[0m         position_embeddings\u001b[38;5;241m=\u001b[39mposition_embeddings,\n\u001b[0;32m    409\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    410\u001b[0m     )\n\u001b[0;32m    411\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(hidden_states)\n\u001b[0;32m    412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m BaseModelOutputWithPast(\n\u001b[0;32m    413\u001b[0m     last_hidden_state\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[0;32m    414\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    415\u001b[0m )\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\tf\\lib\\site-packages\\transformers\\modeling_layers.py:94\u001b[0m, in \u001b[0;36mGradientCheckpointingLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning_once(message)\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\tf\\lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[0;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\tf\\lib\\site-packages\\transformers\\models\\phi3\\modeling_phi3.py:277\u001b[0m, in \u001b[0;36mPhi3DecoderLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, position_ids, past_key_values, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m    276\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[1;32m--> 277\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    278\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresid_mlp_dropout(hidden_states)  \u001b[38;5;66;03m# main diff with Llama\u001b[39;00m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\tf\\lib\\site-packages\\transformers\\models\\phi3\\modeling_phi3.py:60\u001b[0m, in \u001b[0;36mPhi3MLP.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mFloatTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor:\n\u001b[1;32m---> 60\u001b[0m     up_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgate_up_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m     gate, up_states \u001b[38;5;241m=\u001b[39m up_states\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     63\u001b[0m     up_states \u001b[38;5;241m=\u001b[39m up_states \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_fn(gate)\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.cuda import empty_cache\n",
    "from transformers import pipeline\n",
    "torch.cuda.empty_cache()\n",
    "llm = pipeline(\n",
    "                \"text-generation\",\n",
    "                model=\"microsoft/Phi-3-mini-4k-instruct\",  \n",
    "                device='cpu',\n",
    "                dtype=torch.bfloat16\n",
    "                )\n",
    "refined_labels = {}\n",
    "    \n",
    "for topic_id, words in topic_descriptions.items():\n",
    "    refined_labels[topic_id] = refine_topic_label(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33f7b330-eedc-4e07-9bd8-4f581b0f1733",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "856fbf0c-6bba-4471-9a2c-5a6ed93fafe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>17</td>\n",
       "      <td>-1_bosan_sinetron_banget_jalan</td>\n",
       "      <td>[bosan, sinetron, banget, jalan, orang, gopay,...</td>\n",
       "      <td>[kenapa ya kalau nyepi mesti matikan lampu ?! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>0_nya_itu_yang_ini</td>\n",
       "      <td>[nya, itu, yang, ini, tidak, di, saja, jokowi,...</td>\n",
       "      <td>[ya maka dari itu , yang dibilang dari tadi ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>1_tidak_saya_nya_indosat</td>\n",
       "      <td>[tidak, saya, nya, indosat, marah, di, ya, yan...</td>\n",
       "      <td>[halo minimal , kok tidak ditanggal ya , saya ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>2_nya_di_makan_dan</td>\n",
       "      <td>[nya, di, makan, dan, yang, tidak, dengan, mak...</td>\n",
       "      <td>[tempat nya sungguh bagus , suasa nya juga ker...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>3_melelahkan_tidur_mendingan_menyenangkan</td>\n",
       "      <td>[melelahkan, tidur, mendingan, menyenangkan, m...</td>\n",
       "      <td>[hari minggu ya panjang dan melelahkan, senin ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                                       Name  \\\n",
       "0     -1     17             -1_bosan_sinetron_banget_jalan   \n",
       "1      0    115                         0_nya_itu_yang_ini   \n",
       "2      1     54                   1_tidak_saya_nya_indosat   \n",
       "3      2     30                         2_nya_di_makan_dan   \n",
       "4      3     13  3_melelahkan_tidur_mendingan_menyenangkan   \n",
       "\n",
       "                                      Representation  \\\n",
       "0  [bosan, sinetron, banget, jalan, orang, gopay,...   \n",
       "1  [nya, itu, yang, ini, tidak, di, saja, jokowi,...   \n",
       "2  [tidak, saya, nya, indosat, marah, di, ya, yan...   \n",
       "3  [nya, di, makan, dan, yang, tidak, dengan, mak...   \n",
       "4  [melelahkan, tidur, mendingan, menyenangkan, m...   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [kenapa ya kalau nyepi mesti matikan lampu ?! ...  \n",
       "1  [ya maka dari itu , yang dibilang dari tadi ju...  \n",
       "2  [halo minimal , kok tidak ditanggal ya , saya ...  \n",
       "3  [tempat nya sungguh bagus , suasa nya juga ker...  \n",
       "4  [hari minggu ya panjang dan melelahkan, senin ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f26aaf80-7b62-4cf4-9cf8-4f298944cadc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nya', 0.05200474852846109),\n",
       " ('itu', 0.04833900169633662),\n",
       " ('yang', 0.0482272364278341),\n",
       " ('ini', 0.04551919864051053),\n",
       " ('tidak', 0.04439198116743297),\n",
       " ('di', 0.03794677282661403),\n",
       " ('saja', 0.03724966002506158),\n",
       " ('jokowi', 0.03413401432289205),\n",
       " ('sudah', 0.03394987692344164),\n",
       " ('dan', 0.03008658229862419)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10bd18c8-eb0c-4806-be62-b85453aeda8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_modelling_output = topic_modelling_input.copy()\n",
    "topic_modelling_output['topics'] = topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "991a7214-4e18-4a00-8bf0-8dc255bc875a",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_modelling_output.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b4d632-dc4a-4a02-8822-b84d27970875",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "from bertopic import BERTopic\n",
    "topic_model = BERTopic.load('topic_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad6e33fe-521b-4359-9486-090feb8f0f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Extract top words per topic\n",
    "topic_info = topic_model.get_topic_info()\n",
    "topic_descriptions = {}\n",
    "for topic_id in topic_info['Topic']:\n",
    "    if topic_id == -1: \n",
    "        continue\n",
    "    words = [word for word, _ in topic_model.get_topic(topic_id)]\n",
    "    topic_descriptions[topic_id] = \", \".join(words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "166d3425-4a86-4df1-ade0-4176b9585a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f6f759473864ef4852ec3d862610958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Use LLaMA to generate better labels or summaries\n",
    "# Load a local LLaMA (e.g., via Hugging Face if you have access)\n",
    "llm = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"microsoft/Phi-3-mini-4k-instruct\",  # or use \"unsloth/Llama-3.1-8B-Instruct\" for efficient inference\n",
    "    device='cuda',\n",
    "    torch_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7229f01d-ee04-4d05-989f-84e078c2db49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Topic  Count                             Name                CustomName  \\\n",
      "0     -1     26         -1_nya_bosan_kalau_orang  -1_nya_bosan_kalau_orang   \n",
      "1      0    106               0_itu_nya_yang_ini           Jokowi's Policy   \n",
      "2      1     55       1_tidak_saya_indosat_marah             Indosat Anger   \n",
      "3      2     30               2_nya_di_makan_dan     \"Kami Makanan Tidak D   \n",
      "4      3     12  3_melelahkan_kagum_titik_minggu  Efisien Perjalanan Kelas   \n",
      "\n",
      "                                      Representation  \\\n",
      "0  [nya, bosan, kalau, orang, sinetron, saja, yan...   \n",
      "1  [itu, nya, yang, ini, tidak, di, jokowi, saja,...   \n",
      "2  [tidak, saya, indosat, marah, nya, di, yang, a...   \n",
      "3  [nya, di, makan, dan, yang, tidak, dengan, mak...   \n",
      "4  [melelahkan, kagum, titik, minggu, killer, kel...   \n",
      "\n",
      "                                 Representative_Docs  \n",
      "0  [feeling gue karena yang dibahas itu gopay , k...  \n",
      "1  [ya maka dari itu , yang dibilang dari tadi ju...  \n",
      "2  [halo minimal , kok tidak ditanggal ya , saya ...  \n",
      "3  [tempat nya sungguh bagus , suasa nya juga ker...  \n",
      "4  [hari minggu ya panjang dan melelahkan, titik ...  \n"
     ]
    }
   ],
   "source": [
    "def refine_topic_label(top_words: str) -> str:\n",
    "    prompt = f\"\"\"Based on the following key terms, give a short, clear, and general topic name (2-4 words max):\n",
    "    \n",
    "    Key terms: {top_words}\n",
    "    \n",
    "    Topic name:\"\"\"\n",
    "    \n",
    "    response = llm(prompt, max_new_tokens=10, do_sample=False)\n",
    "    # Extract generated text (adjust based on tokenizer/chat template)\n",
    "    generated = response[0]['generated_text'].split(\"Topic name:\")[-1].strip()\n",
    "    return generated.split(\"\\n\")[0].strip()\n",
    "\n",
    "# Apply to each topic\n",
    "refined_labels = {}\n",
    "for topic_id, words in topic_descriptions.items():\n",
    "    refined_labels[topic_id] = refine_topic_label(words)\n",
    "\n",
    "# Update BERTopic\n",
    "topic_model.set_topic_labels(refined_labels)\n",
    "print(topic_model.get_topic_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0071d72f-8383-4b30-897a-3501611cb1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: \"Jokowi's Policy\",\n",
       " 1: 'Indosat Anger',\n",
       " 2: '\"Kami Makanan Tidak D',\n",
       " 3: 'Efisien Perjalanan Kelas'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refined_labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
